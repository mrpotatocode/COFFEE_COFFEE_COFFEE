---
title: |
  ![](mrpotatocode_banner.png){width=7in}  
  Coffee & Machine Learning: An Exploration into the Attributes that Define Single-Origin Coffees
author: "Thomas Rosenthal"
date: "April 1, 2021"
header-includes:
   \usepackage{float}
   \floatplacement{figure}{H}
output:
  bookdown::pdf_document2:
    toc: no
    number_sections: false
    extra_dependencies: ["float"]
    latex_engine: xelatex
    fig_caption: yes
  html_document:
    df_print: paged
  github_document:
nocite: '@*'
bibliography: references.bib
csl: apa-6th-edition.csl
thanks: 'Code and data are available at: [github.com/mrpotatocode/COFFEE_COFFEE_COFFEE](https://github.com/mrpotatocode/COFFEE_COFFEE_COFFEE)'
abstract: In this work, a boosted tree model explores whether combinations of unique coffee attributes can predict the tastes of specialty coffees. The attributes of 550 coffees, collected over a period of four months, include the coffee's country of origin, variety (subspecies), processing method, harvest characteristics (like altitude and season of harvest), and tastes generated through consistent cupping practices. These defining attributes are used as predictors for 22 distinct tasting groups and then compared to actual specialty coffees and found to often match two out of every three tasting groups provided by coffee roasters.  
urlcolor: blue
always_allow_html: true
---

\newpage

```{r setup, echo=FALSE}
set.seed(42)
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, out.extra = "")
options(scipen=99999)
```


```{r libraries}
library(tidyverse)
library(data.table)
library(here)
library(kableExtra)
library(ggplot2)
library(ggthemes)
library(bookdown)
library(rworldmap)
library(treemap)
```

```{r getdata, include=FALSE}
source(paste0(here::here(),"/scripts/build/01_get_data.R"), local = knitr::knit_global())
```

```{r cleandata, include=FALSE}
source(paste0(here::here(),"/scripts/build/02_clean_data.R"), local = knitr::knit_global())
```

```{r modeldata, include=FALSE}
source(paste0(here::here(),"/scripts/analyze/03_xgb_model.R"), local = knitr::knit_global())
```

```{r vizdata, include=FALSE}
source(paste0(here::here(),"/scripts/analyze/04_viz_data.R"), local = knitr::knit_global())
```

## Introduction

Coffee is consumed in every country, is the seventh most valuable agricultural product [@Pendergrast_2010], and supports the livelihood of 125 million people [@Hoffmann_2018] around the world. In many places, the daily coffee ritual signifies a start to the day and a nod to the productive buzz it imbues its consumer. Our appreciation for coffee has helped shape a complex landscape of horticulture, chemistry, food science, and globalised import-export economics. As a result, coffee has never tasted better. Our collective understanding of coffee information has led to phenomenal quality coffee beans and annual championships celebrating the labour and toil of farmers, producers, roasters, and baristas across the world.

### Background

Combining coffee and data science, this exploratory research aims to examine whether a specialty coffee’s Tasting Notes can be predicted by a gradient boosted algorithm based on the coffee's attributes (§Terminology). Several key research studies have explored the relationship between single-origin attributes and their Tasting Notes and thus sit as domain framework for technical applications made here. Exploring Tasting Notes is contingent firstly upon the acceptance of Tasting Notes as objective rather than subjective. This phenomenon has been well-noted by vintners and has likewise been researched with regard to specialty coffee [@Croijmans_Majid_2016]. Research using blind taste and aroma tests generally supports consistency across highly trained panel tasters [@Bhumiratana_Adhikari_Chambers_2011]. The conclusions of Croijmans and Bhumiratana support the contention that Tasting Notes are a combined result of cupping experts’ training and linguistic ability to identify tastes through plain nomenclature. For example, "A sour, sweet fruity aromatic that may be somewhat dark, musty and earthy, reminiscent of dark fruits and root vegetables such as beets and carrots [which] may also have an astringent mouthfeel" is identified as _Pomegranate_ [@SensoryLexicon]. Cupping, following protocols published by the Specialty Coffee Association (2003), serves as the only means for Tasting Note generation across all relevant studies. Standardized cupping routines were thoroughly explored as a case study in Rwanda [@Goldstein_2011] and found to be reliable.

As such, this project is firmly rooted in scientific consensus that Tasting Notes are consistent in their generation and thus measurable by machine learning models. From this assertion, two previous experiments have explored single-origin coffee Tasting Notes. Firstly, _Coffee Terroir: Cupping Description Profiles and Their Impact Upon Prices in Central American Coffees_ [@Conley_Wilson_2018] combined Country of origin and Tasting Notes within a Multiclass Classification Neural Network and examined the attribute coefficients via regression analysis. Secondly, a research blog produced by Jonathan Gagné (2019) at the University of Montreal exemplifies Varietal:Tasting Note and Processing:Tasting Note relationships.

This work aims to reinforce the anecdotal assumption that curation of specialty coffees creates certain tastes. The industry cultivates (even without intention) a collection of expected Tasting Notes for known attribute combinations that are perceived to be desirable by consumers, thus reinforcing the industry’s expectations and further cultivation of Tasting Notes. The results and implications of modelling are important within the coffee industry; if known attribute combinations directly contribute to desirable Tasting Notes, producers may know the value of a crop before buying and roasting. This in turn affects coffee farmers, as desirability has a noted effect on price; Traore et al. (2018) highlighted this phenomenon for Pacamara and Caturra varieties.

### Terminology	

As the world’s appetite for coffee has grown, the coffee industry's "Third Wave" movement has flourished. The movement aims to treat coffee as an artisanal product that is carefully curated, where coffee quality is maximized at each stage: farming, producing, roasting, and selling [@Rosenberg_Swilling_Vermeulen_2018]. There is an “obsession” with coffee’s taste and an often-altruistic approach to conducting business [@Pendergrast_2010]. At its pinnacle, single-origin specialty coffee exists beyond a means to caffeinate and instead engages an increasingly discerning consumer.

Under the umbrella term "Third Wave", coffees within this project are those that have been produced at a "single origin": coffee that is sourced from a single producer, farm, or crop. These coffees are further graded as "specialty coffee": coffee of the species _Coffea arabica_ that is within the top 20% of graded coffee produced worldwide. Two grading systems are generally utilized: Q-grading, as defined by the Specialty Coffee Association, and sieve grading, where larger beans are generally preferred. Different countries utilize different grades (e.g. AA, 16+, Strictly High Grown, Extra Fancy) but top grades are well distinguished from middle- and commodity-grade coffees [@Hoffmann_2018]. 

Single-origin coffees are intended to be traceable, meaning consumers are privy to the production cycle before purchase. This data is represented by a core of common attributes: 1) Country and Region of production; 2) Variety; 3) Harvest characteristics; 4) Processing; 5) Taste; and 6) Roast. Full descriptions of these attributes and their definitions can be found in Appendix A.

## Data

No publicly available coffee dataset was available for this project and so one was built. **Figure \@ref(fig:workflow)** shows the end-to-end process employed to collect, analyse, model, evaluate, and present this data. This comprised of several web scraping processes (§Data Collection) that were then automated and combined into a stable dataset. This dataset was placed alongside a conformed set of Tasting Notes (§Data Conformity) before modelling.

```{r workflow, fig.align="center", fig.cap="Coffee Model Workflow"}
DiagrammeR::grViz(paste0(here::here(),"/scripts/analyze/05_model_flow.dot"))
```

### Data Collection

Coffee data was scraped from five websites over the course of four months, comprising of 550 unique coffees from 106 roasters. Data scraping varied by website format: some websites organized each coffee by roaster, so several scrapers were built to scrape data from each roaster with consistent formatting across weeks; others were large collections of coffees that were scraped in entirety from top to bottom. Websites were selected by ease of scraping and quality of coffee offerings. Scrapers were generally run once a week, and duplicate coffees were discarded if there were any. Attributes varied by websites and roaster, but core attributes were generally present. Coffees marked as blends, espressos, and/or decaf were removed.  

These scrapers were automated with GitHub Actions to run on a weekly or monthly basis, depending on the frequency at which the coffees were updated on their respective websites. Each scraper produced a .csv file per roaster or site. These .csv files were then added to the existing data and any duplicates removed. One website, not suitable for scraping but of excellent data richness, had coffee data manually collected from it. Coffee models became significantly more reliable around 500 coffees, so this manual collection was necessary to help reach this threshold within the time frame allowed. 

Data collection proved a major limitation to this project. Coffee data collection should continue throughout the year to accommodate distinct coffee harvesting seasons throughout the world. For example, Brazil (the world's largest producer of arabica grade beans) is significantly underrepresented due to the timing of data collection. Furthermore, scraped websites were inconsistent in their coffee listings. Coffee attributes present in one week were not guaranteed for the next, and the order in which the attributes were listed varied from week to week. Data that was unable to conform to the established standards was discarded before modelling in order to prevent erroneous variable relationships (such as a Country being listed as a Process).

### Data Conformity   

To facilitate the primary focus of this work (predicting Tasting Notes), a conformed table based on the Specialty Coffee Association Taster's Flavor Wheel (2016) (**Figure \@ref(fig:flavorwheel)**) and World Coffee Research Sensory Lexicon (2017) created a hierarchical categorization for Tasting Notes. Tasting Notes were placed into larger Tasting Groups. Tasting Groups were placed into larger Tasting Traits. **Table \@ref(tab:SCAfru)** provides a sample of this relationship for six Tasting Notes within the "Fruity" Tasting Trait. 

![(#fig:flavorwheel) Specialty Coffee Association Taster's Flavor Wheel (Courtesy SCA and WCR, Creative Commons Licensing)](./imgs/Coffee_Tasters_Flavor_Wheel.png){width=50%}

```{r SCAfru}
citr <- sample(x = SCAA_Notes %>% filter(Trait == 'Fruity') %>% 
                                 select(Note) %>%unique() %>% unlist(),
                                 size = 6, replace = FALSE)
SCAA_Fake <- subset(SCAA_Notes, Note %in% citr) %>% select(-l_note) %>% 
        mutate(Note = str_to_title(Note)) %>% rename_all( ~ paste0("Tasting ", .x))
kable(SCAA_Fake, caption="Sample SCA Tasting Wheel Rows", booktabs = TRUE, linesep= "") %>% 
  kableExtra::kable_styling(latex_options = c("stripped", "HOLD_position"))
```

New Tasting Notes were added each time new data was added to the dataset. A total of 577 Tasting Notes exist within 31 Tasting Groups and 10 Tasting Traits. **Figure \@ref(fig:lollipops)** shows the number of Tasting Notes in each Tasting Group, where Tasting Traits are represented by each coloured dot. Not all Tasting Notes were observed within the dataset: some were listed by the Specialty Coffee Association Taster's Flavor Wheel, others were added in anticipation of future coffees (for example, adding Raspberry Jam after Strawberry Jam was observed in the dataset). 427 distinct Tasting Notes were observed in the dataset.
  
```{r lollipops, out.width="66%", fig.align="center", fig.cap="Hierarchy of Tasting Notes, Groups, and Traits"}
g <- SCAA_Notes %>% group_by(Trait,Group) %>% summarise(n=n()) %>% arrange(desc(n)) %>% rename(`Tasting Trait` = Trait) 
legend_title <- "OMG My Title"

ggplot(g, aes(x=reorder(Group, n) ,y =n, colour = `Tasting Trait`, fill = `Tasting Trait`))+
  #geom_bar(stat="identity") +
  geom_segment(aes(xend=Group, yend=0), colour = "grey") +
  geom_point(size=3.2) +
  ylab("Number of Tasting Notes") +
  xlab("Tasting Group") +
  coord_flip() + 
  theme_clean() +
  #scale_colour_manual(values = c("#372772","#f19953","#0075f2","#e15554","#86bbd8","#fde8c3","#748b75","#730f07","#da8c07","#280003"))
  #scale_colour_manual(values = c("#280003","#034732","#bb4430","#7daf8f","#00458f","#bc9cb0","#f19953","#730f07","#86bbd8","#da8c07"))
  #scale_colour_manual(values = c("#730f07","#034732","#280003","#7daf8f","#bc8e5c","#70b5ff","#bc9cb0","#f19953","#86bbd8","#da8c07"))
  #scale_colour_manual(values = c("#220901","#941b0c","#af3508","#f6aa1c","#034732","#47745c","#8ba085","#86bbd8","#2660a4","#372772"))
  #scale_colour_manual(values = c("#280003","#606d5d","#bc9cb0","#86bbd8","#f6ae2d","#bb4430","#ffe1a8","#2660a4","#f19953","#372772"))
  scale_colour_brewer(palette="Spectral")
  #scale_fill_brewer(palette="PRGn") 
```

Adding Tasting Notes to the conformed table introduces some subjectivity. While many Tasting Notes were obvious (e.g. Black Currant is a Berry Fruit), others were difficult to place within a single category (e.g. Chocolate Orange). Attempts were made to avoid adding any Tasting Traits or Tasting Groups, instead finding space within existing Tasting Groups. Furthermore, some coffee Tasting Notes were less standard, occasionally showing regionality (e.g. _Pouding Chomeur_ from a Montreal roaster) or brand names (e.g. Kit-Kat). This limitation had less impact in the model of this study, which predicted Tasting Groups rather than individual Tasting Notes, but would need to be addressed for future models (§Next Steps) by larger dataset volume and/or stricter Tasting Note filters (i.e. only accepting certain standard values).

Additionally, the World Coffee Research program's Arabica Coffee Varieties (2019) catalog was used to help standardize coffee Varieties. Because the catalog does not cover all Countries within the dataset, the most frequent Varieties from those Countries were included in modelling. Less frequent Varieties, when valid, should be included as the dataset grows. A total of 15 distinct Varieties were used in the modelling process.

### Dataset

Scraped .csv files were flexible enough to allow for significant variance in coffees. By nature, coffees are curated by humans; their coffee cherries harvested at various Ripeness points, their Varieties occasionally blended to offset flavours, their Processing sometimes including a collection of multiple nearby farms. Producers and roasters make an effort to make these variables as transparent as possible. To create a standardized approach to the information rich data, data extraction focused on specific and recurring features. In total 25 different attributes were collected, but many of these were extremely sparse (less than 1%) and were not used within modelling. 

First, Tasting Notes in both the dataset and the conformed table were stemmed using the `SnowballC` package [@SnowballC]. This removed the need to explicitly list both plural and nonplural forms of Tasting Notes (e.g. Strawberry, Strawberries). Tasting Notes were also matched using ASCII/TRANSLIT so that accented characters were not matched indiscriminately to non-accented characters (e.g. Rosé, Rose).

Second, the variable Ripeness was extracted from both Variety and Process columns. Ripeness is expressed by colouration (Pink, Red, Yellow, Orange, White, Black) as a modifier to either column (e.g. Pink Bourbon, Black Honey). 

Third, Altitude, which was typically expressed in Metres Above Sea Level (MASL), was converted to a numeric value. Values that were presented as a range were averaged (e.g. 2000-2100 = 2050). 

Finally, both Variety and Process columns were parsed in cases where more than one value was presented. This was fairly common for Variety, where single-origin farms blend small quantities of other Varieties with a primary Variety (e.g. Caturra + Colombia + Castillo becomes three columns: Variety1, Variety2, Variety3). It is assumed these values are listed from greatest to least, as occasionally the percentage of each Variety is specified, and in these cases the primary Variety has always been listed first. These coffees are generally not considered blends when produced by the same farm or producer. Process columns similarly can describe secondary Processes performed after main Processes (e.g. Washed + Patio Dried becomes two columns: Processing1, Processing2). In these instances, the secondary Process describes the drying method, rather than the Processing method. In other instances, the secondary Process was a synonym for the primary (e.g. Natural + Dry Processed, where, by definition, Natural is a Dry Processing method). The model used only the primary values for both Variety and Process.

Future models aim to incorporate Regions within Countries using a conformed table to create additional nuance; regional differences are well-noted by Hoffmann (2018). Similarly, in instances where Country was not explicitly listed, but rather presumed by Region, a conformed process could provide missing data (e.g. Huehuetenango would indicate Guatemala).

**Figure \@ref(fig:map)** shows coffee frequency by Country prior to frequency filters required by modelling. Ethiopia and Columbia are the most frequent Countries in the dataset; this is to be expected considering when the data was collected, as Ethiopia and Columbia both have multiple growing seasons that coincided with the data collection period. A total of 25 Countries were represented in the data, out of the 35 coffee-growing Countries discussed by Hoffmann (2018). Hoffmann speaks to several of these countries having extremely limited production, especially for specialty-grade arabica beans, and thus their omission is unsurprising (e.g. Vietnam). 

```{r map, out.width="66%", fig.align="center", fig.cap="Map of Coffees from Each Country in the Dataset"}
mapParams <- mapCountryData(Map, 
                   nameColumnToPlot="n",
                   xlim=bbox(xylims)[1,],
                   ylim=bbox(xylims)[2,],
                   catMethod="pretty",
                   addLegend=FALSE,
                   colourPalette=colourPalette,
                   mapTitle = '',
                   missingCountryCol = gray(.8))

do.call(addMapLegend, c(mapParams,
                       legendWidth=0.75,
                       legendIntervals="data",
                       legendMar=2,
                       legendShrink =0.4))
abline(h=0,lty=2,col='grey')

```

In order to produce higher accuracy within models, extremely infrequent Processes, Countries, and Varieties were excluded. This threshold was set at five individual occurrences for each variable. This had a significant effect on the number of Ethiopian coffees included in the model dataset. Ethiopia has a long history of unique Varieties, some of which are endemic to Ethiopia, and the Variety lineage is less established. **Table \@ref(tab:topfreq)** shows the most frequent Countries, Varieties, and Processes following this filtering process.

```{r topfreq}
topfreq_var <- pre_prep_data %>% ungroup() %>% mutate_all(funs(str_to_title(.))) %>% 
  group_by(Variety1) %>% summarize(n = n()) %>% arrange(desc(n)) %>% top_n(6)
topfreq_cont <- pre_prep_data %>% ungroup() %>% mutate_all(funs(str_to_title(.))) %>% 
  group_by(Country) %>% summarize(n = n()) %>% arrange(desc(n)) %>% top_n(6)
topfreq_proc <- pre_prep_data %>% ungroup() %>% mutate_all(funs(str_to_title(.))) %>%
  group_by(Processing1) %>% summarize(n = n()) %>% arrange(desc(n)) %>% top_n(6)

kable(list(topfreq_cont,topfreq_var,topfreq_proc),
      caption="Frequent Varieties, Countries, and Processes", booktabs = TRUE, linesep= "") %>% 
  kableExtra::kable_styling(full_width = FALSE, position = "left") %>% 
  kableExtra::kable_styling(latex_options = "HOLD_position")
```

When Country, Variety, and Process are combined, **Table \@ref(tab:freqcombo)** shows that Columbia + Caturra + Washed coffees are the most frequent. Four of the six most frequent Countries and Varieties are present in the most frequent combinations of attributes; only two distinct Processes are present. 

```{r freqcombo}
freqcombo <- unite(pre_prep_data, ItemSet, Country,Variety1,Processing1, sep = " + ") %>% group_by(ItemSet) %>% 
            summarize(n = n()) %>% arrange(desc(n)) %>% top_n(6) %>% mutate_all(funs(str_to_title(.)))
kable(freqcombo, caption="Greatest Combination Frequencies", booktabs = TRUE, linesep= "") %>% 
  kableExtra::kable_styling(latex_options = c("stripped", "HOLD_position"))
```

Processing has a dramatic effect on Tasting Notes [@Hoffmann_2018], and despite large imbalances in unique Processing frequency, the variable is essential to include within modelling. This effect can be observed in the dataset when a roaster offers two distinct Processes for a coffee that is otherwise the same and presents two distinct sets of Tasting Notes (**Table \@ref(tab:twocoffees)** as an example). 

```{r twocoffees}
PistaFugi <- data %>% filter(Roaster == 'Pista') %>% filter(Coffeename %like% 'Fugi') %>% 
  mutate_all(funs(str_to_title(.))) %>% select(Roaster, Coffeename, Country, Region, Variety, Processing, Tastingnotes) %>% 
  rename(`Coffee Name` = Coffeename, `Tasting Notes` = Tastingnotes)

kable(PistaFugi, caption="Two Different Processed Coffees", booktabs = TRUE, linesep= "") %>% 
  kableExtra::kable_styling(latex_options = c("stripped", "HOLD_position"))
```

As expressed previously, adding Region to models was desirable. However, combination frequencies (**Table \@ref(tab:freqcomboregion)**) demonstrate the limitations of a dataset this size, where very few Regions had more than five occurrences when combined with Variety and Process. 

```{r freqcomboregion}
freqcomboregion <- data %>% distinct() %>% mutate_all(funs(str_to_title(.)))

kable(unite(freqcomboregion, ItemSet, Country,Region,Variety1,Processing1, sep = " + ") %>% 
        group_by(ItemSet) %>% summarize(n = n()) %>% arrange(desc(n)) %>% filter(n > 5), 
      caption="Combination Frequencies with Region > 5", booktabs = TRUE, linesep= "") %>% 
  kableExtra::kable_styling(latex_options = c("stripped", "HOLD_position"))
```

This sparseness in data also affected the model's ability to predict Tasting Notes. Instead, Tasting Groups were determined to be the next best candidate for prediction, having considerably more nuance than Tasting Traits but still frequently occurring for nearly all class labels. As such, for all coffees in the dataset, Tasting Groups were stacked so that a single Tasting Group column was the predictor. This process is demonstrated as **Table \@ref(tab:premeltsample)** transforms into **Table \@ref(tab:meltsample)**.  

```{r premeltsample}
sample4 <- pre_prep_data %>% ungroup() %>% mutate(idx = rownames(pre_prep_data)) %>% 
  filter(idx == 4) %>% mutate_all(funs(str_to_title(.))) %>% select(-idx) %>% select(Country, everything()) %>% 
  rename(TastingGroup1 = Group1, TastingGroup2 = Group2, TastingGroup3 = Group3)


kable(sample4, caption="Coffee Sample before Stacking", booktabs = TRUE, linesep= "") %>% 
  kableExtra::kable_styling(latex_options = c("stripped", "HOLD_position"))
```

```{r meltsample}
sample4melt <- pre_prep_data %>% ungroup() %>% mutate(idx = rownames(pre_prep_data)) %>% filter(idx == 4) %>% 
  select(-idx) %>% melt(id.vars=1:3) %>% select(-variable) %>% rename(TastingGroup = value) %>% 
  mutate_all(funs(str_to_title(.))) %>% select(Country, everything())

kable(sample4melt, caption="Coffee Sample after Stacking", booktabs = TRUE, linesep= "") %>% 
  kableExtra::kable_styling(latex_options = c("stripped", "HOLD_position"))
```

**Figure \@ref(fig:tastingfrequencyplot)** shows the frequency of all Tasting Groups following this transformation prior to modelling. Seven Tasting Groups—Other Fruit, Brown Sugar, Stone Fruit, Berry Fruit, Cocoa, and Floral—are much more prominent than other Tasting Groups. This imbalance has a strong influence on the model (§Results), as very few coffees are predicted with Tasting Groups aside from these seven. However, some Tasting Notes are rare for coffees as a whole, but highly frequent for specific coffee attribute combinations. For example, Black Tea is an often-curated Tasting Note for Ethiopian coffees [@Hoffmann_2018]. As such, the lack of presence within the overall dataset does not indicate that a given Tasting Group will not be predicted.

```{r tastingfrequencyplot, out.width="66%", fig.align="center", fig.cap="Tasting Group Frequency Prior to Modelling"}
g1 <- prep_data %>% group_by(TastingGroup) %>% summarize(n = n()) %>% arrange(desc(n))
g1$Prop <- g1$n/sum(g1$n)

ggplot(g1, aes(x=reorder(TastingGroup, n) ,y =n))+
  geom_bar(stat="identity", fill = "#733524") +
  ylab("Frequency") +
  xlab("Tasting Group") +
  coord_flip() + 
  theme_clean()
```


## Model

Using `tidymodels` [@tidymodels], a workflow was developed wherein a Gradient Boosted Tree model with an `XGBoost` [@xgboost] engine predicted Tasting Groups using Country, first Varietal, and first Process for all coffees (Predictors: _Variety1_, _Processing1_, _Country_; Outcome: _TastingGroup_). The dataset was split into training and testing sets using a 75/25 non-stratified split. All predictor values were converted to dummy values (as they were all nominal). The Gradient Boosted Tree was tuned using grid search hyperparameterization on the number of trees (trees), the splitting criteria for each node (min_n), the maxiumum depth of trees (tree_depth), and the learning rate between iterations (learn_rate). 256 total parameter combinations were run (four parameters with four selections each, 4^4). During grid search, 10-fold cross validation was performed. The model was then evaluated on the testing dataset before the best parameter set was selected based on the highest ROC AUC (accuracy under curve) value. The finalized model was then fit to the entire dataset.

XGBoost [@xgboostpaper] uses the same principals as other Gradient Boosted Trees: loss minimization through gradient descent. XGBoost balances the need to explore all base learners (training loss) and the performance requirements of calculating a loss function for each point of gradient descent (regularization). This is achieved by calculating a residual similarity score after each leaf splitting criteria is evaluated. The node with the greatest information gain (maximum loss reduction) is selected greedily (so not all trees or learning rates are explored). As an ensemble model, each coefficient term is added to the previous to adjust error rates created by previous model iterations.

The final prediction, achieved by fitting base learners to the minimum loss by gradient descent, is as follows:
$$\hat{y_i} = \sum_{k=1}^Kf_{k}(x_{i})$$

* $\hat{y_i}$ is the predicted value
* $K$ is the number of K additive functions used to predict the output
* $f_{k}$ is the space of trees (structure: depth, leaf weight)
* $x_{i}$ is the set of attributes defining the tree (the dataset).

Trees are defined by their splitting criteria (leaf weight) and structure (tree depth), such that:
$$f_{t}(x_{i}) = w_{q(x)}$$

* $w$ is the leaf weight
* $q(x)$ is the tree structure.

XGBoost seeks to minimize its regularized function:
$$L(\phi) = \sum_{i}l(\hat{y_i},y_i) + \sum_{k}\Omega(f_{k})$$

* $l(\hat{y_i},y_i)$ is the difference between prediction and actual

plus a loss coefficient (learning rate) as:
$$\Omega(f_t) = \gamma T + \frac12\lambda \sum_{j = 1}^T w_j ^2$$

* $\Omega(f_t)$ is the loss coefficient applied to the tree
* $\gamma T$ is the number of leaves in the tree
* $\frac12\lambda \sum_{j = 1}^T w_j ^2$ is the Euclidean norm for leaf scores.

The ensemble method is then calculated through boosting:

* $\hat{y_i}^{(0)}$ = 0
* $\hat{y_i}^{(1)}$ = $\hat{y_i}^{(0)} + f_{1}(x_{i})$
* $\hat{y_i}^{(2)}$ = $\hat{y_i}^{(1)} + f_{2}(x_{i})$

until finalized terms are added to the model:
$$\hat{y}^{(t)} = \sum_{i=1}\lambda(y_i,\hat{y_i}^{(t-1)} + f_{t}(x_i)) + \Omega(f_{t})$$

* $\hat{y}^{(t)}$ is the model at training
* $\sum_{i=1}\lambda(y_i,\hat{y_i}^{(t-1)} + f_{t}(x_i))$ adds each boosting function, including the functions added in previous iterations ($\hat{y_i}^{(t-1)}$)
* $f_{t}(x_i)$ as the new function
* $\Omega(f_{t})$ as the loss coefficient previous calculated.

As such, **Table \@ref(tab:bestparams)** shows the best selected parameters for the model following hyperparametization through grid search and optimized for ROC AUC.

```{r bestparams} 
kable(boosted_param %>% select(-'.config'), caption="XGBoost Model Parameters", booktabs = TRUE, linesep= "") %>% 
  kableExtra::kable_styling(latex_options = c("stripped", "HOLD_position"))
```

## Results

The Gradient Boosted Tree model produces ranked predictions (from most to least probable) for 22 Tasting Groups. Because most coffees have three Tasting Notes, the model's three most probable predictions are treated as the overall prediction for any given combination of coffee attributes. Not all Tasting Groups were predicted, generally due to sparsity or lack of ability to differentiate coffees with unique Tasting Groups from coffees with the same attributes and more typical Tasting Groups. **Table \@ref(tab:tgroupaccu)** shows the most frequent predictions compared to their actual frequencies. Other Fruit, a catch-all category for the myriad of fruits that present themselves in coffees, is both the most frequent Tasting Group in the dataset and the most predicted by the model. The model overestimates the top four Tasting Groups (Other Fruit, Brown Sugar, Stone Fruit, Citrus Fruit) compared to their actual frequencies in the dataset.

```{r tgroupaccu}
pred_freq <- final_accuracy %>% group_by(note) %>% summarise(n = n()) %>% arrange(desc(n)) %>% 
  rename('TastingGroup' = note)
pred_freq$Prop <- pred_freq$n/sum(pred_freq$n)

tgroup_accu <- inner_join(pred_freq, g1, by = 'TastingGroup') %>% select(-n.y) %>% 
  rename('Predictions' = n.x, 'PredictionFreq' = Prop.x, 'ActualFreq' = Prop.y)

kable(tgroup_accu %>% mutate(across(is.numeric, ~ round(., 3))), 
      caption="Model Prediction by Tasting Group", booktabs = TRUE, linesep= "") %>% 
  kableExtra::kable_styling(latex_options = c("stripped", "HOLD_position"))
```

A confusion matrix (**Figure \@ref(fig:confmat)**) run on the conserved test data appears to show that only seven Tasting Groups were predicted. These Tasting Groups coincided with the most frequently occurring Tasting Groups (as shown by **Figure \@ref(fig:tastingfrequencyplot)**). Like **Table \@ref(tab:tgroupaccu)**, Brown Sugar and Other Fruit classes were the most highly predicted results. But confusion matrices only show the most probable prediction for each coffee within the test data. The overall accuracy metrics that can be derived from this confusion matrix are thus quite low. Berry Fruit, for example, appeared 22 times within the test data, six of which were predicted correctly out of 29 total predictions: a precision rate of 0.207 and a recall rate of 0.273. Some classes were never predicted correctly as the most probable prediction (e.g. Dried Fruit). 

![(#fig:confmat) Confusion Matrix](./imgs/confusion_matrix.png){width=70%}

However, both **Table \@ref(tab:tgroupaccu)** and the confusion matrix are poor representations of the model's performance, and the accuracy score for the model cannot be conventionally calculated. Instead, a better accuracy metric must measure the three most probable predictions while simultaneously deemphasizing the order in which Tasting Groups appear. These needs are specific to coffee: Tasting Group order is irrelevant because there is neither standardization (e.g. fruits are not listed before sugars) nor hierarchy (i.e. the first note is not more prevalent than the second). Therefore, the most probable prediction does not need to coincide with the first of three Tasting Groups.

All possible unique inputs were provided to the model, and the top three most probable predictions were tabulated alongside their actual (truth) values. A Boolean flag checked whether the first predicted value was in any of the three Tasting Groups. This process was repeated for the second and third predicted values. This method also correctly predicts Tasting Groups for coffees that do not have three unique Tasting Groups. Tasting Groups do not need to be unique because they represent Tasting Notes that are unique (e.g. Black Currant and Raspberry are both Berry Fruits, therefore both the first and second Tasting Group would be Berry Fruit). Because the model cannot predict the same Tasting Group twice, the Boolean flag allowed duplicate Tasting Groups found within a given coffee to be counted for each actual occurrence of a Tasting Group, as if the model had predicted duplicate values. An example coffee (**Table \@ref(tab:sampleaccu)**) demonstrates the recalculated accuracy metric. For a coffee with given Country + Variety + Process attributes: Rwanda + Bourbon + Honey, predictions were Brown Sugar, Other Fruit, and Stone Fruit. Actual values were Brown Sugar, Other Fruit, and Other Fruit. Because the model has predicted both Brown Sugar and Other Fruit, the accuracy is 100% for the given set of coffee attributes. 

```{r sampleaccu}
sample_accu <- final_accuracy %>% select(-id) %>% 
  filter(Country == 'rwanda', Variety1 == 'bourbon',Processing1 == 'honey') %>% arrange(idx) %>% 
  select(-Variety1,-Processing1,-Country)

sample_accu <- sample_accu %>% select(-idx) %>% rename("Prediction" = note, "Probability" = value,
                    'TG_Actual1' = Group1,  'TG_Actual2' = Group2, 'TG_Actual3' = Group3, 
                    'TG_Correct1' = Group1_c, 'TG_Correct2' = Group2_c, 'TG_Correct3' = Group3_c) %>% 
  mutate(across(is.numeric, ~ round(., 3)))

kable(sample_accu, caption="Rwanda + Bourbon + Honey Accuracy Measurement", booktabs = TRUE, linesep= "") %>% 
  kableExtra::kable_styling(latex_options = c("stripped", "scale_down", "HOLD_position"))
```

Thus, the total number of true predictions was 534 of 1188 for a model accuracy score of 44.949% (**Table \@ref(tab:accu)**). 

```{r accu}
#model accuracy:
accu <- correct_predictions %>% filter(Var1 == TRUE, Var2 %like% '_c') %>% select(-Var1) %>% transpose(make.names	='Var2')

accu$Correct <- as.numeric(correct_predictions %>% filter(Var1 == TRUE) %>% summarize(freq = sum(Freq)))
accu$Total <- nrow(final_accuracy)
accu$Accuracy <- as.numeric(accu$Correct/accu$Total)

kable(accu %>% mutate(Accuracy = sprintf("%0.3f%%", accu$Accuracy * 100)),  
      col.names = c('TG_Correct1','TG_Correct2','TG_Correct3','TotalCorrect','TotalTastingGroups','Accuracy'), 
      caption="Adjusted Model Accuracy", booktabs = TRUE, linesep= "") %>% 
  kableExtra::kable_styling(latex_options = c("stripped", "HOLD_position"))

```

### Shiny App

The model was placed in a Shiny App (**Figure \@ref(fig:shiny)**) to allow exploration of any given attribute combination. 98 distinct selections are possible, consisting of 20 Countries, 15 Varieties, and 5 Processes. The Shiny App requires a user to first select a Country from a dropdown and then provides the list of possible Varieties within that Country. Processes are then filtered based on Variety selection. Combinations that did not exist within the dataset could not be passed to the model (as many of these would not occur in the real world, and thus predictions would be irrelevant).

The top three model predictions were listed alongside their probability for occurring. For example, a Kenya + SL28 + Washed selection shows a prediction of Other Fruit (21%), Berry Fruit (19%), and Citrus Fruit (11% probability). A new set of parameters could be selected at any time. The Shiny App does not show model accuracy or the degree that Tasting Groups vary within the given set of attributes (§Findings and Implications) in its current design; this should be added in the future in order to give a better sense of confidence to predictions beyond probability. 

![(#fig:shiny) Tasting Note Predictions Shiny App](./imgs/shiny_app.png){width=70%}

The Shiny app was deployed using shinyapps.io by RStudio and is available at: https://mrpotatocode.shinyapps.io/TastingNotePredictions/.

## Discussion

While the results of this study were limited by the size of the dataset, the data scrapers and models developed will provide a solid foundation for future research. Evaluating the significance of this work is difficult, but models for certain combinations appear to meet known expectations and are comparable to previous work by Gagné (Varietal + Process to predict Tasting Notes) and Conley and Wilson (Country to predict Tasting Notes). 

Gagné produced flavor wheels for five common Varieties (Bourbon, SL28, Heirlooms, Caturra, Geisha) of Washed coffees, and word clouds for 14 Varieties and 11 Processes (five of which were Ripeness + Honey, and two other infrequent but well-known processes - carbonic and anaerobic). Gagné's work did not include prediction, but rather frequency visualizations of 1500 coffees. When comparing these flavor wheels to the model, two matches stand out: Kenya + SL28 + Washed is predominantly Berry Fruit with Other Fruit and Citrus Fruit Tasting Groups (see **Figure \@ref(fig:shiny)** for model output); similarly, Ethiopia + Heirloom + Washed is predominantly Floral with Stone Fruit and Citrus Fruit, though Black Tea was not predicted as the dominant Tasting Group. It is difficult to compare results beyond SL28 and Heirloom Varieties, which appear almost exclusively in Kenya and Ethiopia, respectively. Varieties that appear throughout the world, such as Bourbon or Caturra, have much more variety in their predictions than Gagné's work, which generalizes Bourbon regardless of Country of origin. Gagné's work cannot be compared to model predictions for Processes other than Washed.

Conley and Wilson’s models classified Costa Rican Tasting Notes as Stone Fruit (Cherry), Sweet/Brown Sugar (Sugar Cane, Brown Sugar, Syrup, Sweet), and Vanilla. Without knowing either Variety or Process, the best way to draw comparisons with the model was to find the most commonly occurring Costa Rican coffees in the dataset: Caturra + Washed, Caturra + Natural, Caturra + Honey, and Catuai + Washed. Of these, all predictions produced Brown Sugar as a Tasting Group, and three of four produced Stone Fruit (**Table \@ref(tab:costarica)**). Because Conley and Wilson have used a very small subset of Tasting Notes, placing them within Tasting Groups potentially eliminates the nuance of their analysis, while substituting the complexity of this model. This may suggest that coffees are easier to overgeneralize than specifically predict, but without a greater number of Tasting Notes and more specificity of Variety and Process, it is hard to differentiate the model results from one another.  

```{r costarica}
#create the itemset variable
comp_t <- pre_prep_data %>% unite(., ItemSet, Country,Variety1,Processing1, sep = " + ", remove = FALSE) %>% ungroup()

#get the four most frequent itemsets for costa rica
cr_4 <- comp_t %>% filter(Country == 'costa rica') %>% group_by(ItemSet) %>% summarize(n = n()) %>% top_n(4)

#push the variables into model
comp_t <- comp_t %>% filter(ItemSet %in% cr_4$ItemSet) %>% select(Variety1, Processing1, Country) %>% distinct()

#get predictions
cr_preds <- data.frame()
for(i in 1:nrow(comp_t)){
  answer <- predict(
    final_boosted_model,
    comp_t %>% dplyr::slice(i),
    type = "prob"
  ) %>% 
    gather() %>% 
    arrange(desc(value)) %>% 
    top_n(3) %>% 
    mutate(idx = row_number())
  
  #bind
  cr_preds <- rbind(cr_preds,answer)
}

#add an id for each prediction
cr_preds$id <- c(0, rep(1:(nrow(cr_preds)-1)%/%3))
#adjust so first id = 1 instead of 0
cr_preds$id <- cr_preds$id+1

#remove the label ".pred_" produced by the predict() fx
cr_preds <- cr_preds %>% 
  mutate(note = key %>% str_remove(".pred_"), .keep = "unused")

#move note to the first column
cr_preds <- cr_preds %>% select(note, everything()) %>% select(-value)

#merge back to comp_t so we have the coffee details associated with each predictions 
cr_preds <- merge(cr_preds,mutate(comp_t, id = rownames(comp_t)))

#prepare the final table
cr_pred_fin <- cr_preds %>% pivot_wider(names_from = idx ,values_from = note) %>% select(Country, everything()) %>% 
  select(-id) %>% rename(TG_Pred1 = `1`, TG_Pred2 = `2`, TG_Pred3 = `3`) %>% 
  mutate_all(funs(str_to_title(.))) %>% unite(., ItemSet, Country,Variety1,Processing1, sep = " + ")

kable(cr_pred_fin, caption="Most Frequently Occurring Costa Rican Coffee Predictions", booktabs = TRUE, linesep= "") %>% 
  kableExtra::kable_styling(latex_options = c("stripped", "HOLD_position"))
```

Since the combination of these two bodies of work has not yet been established elsewhere, the model provides a rudimentary framework for more multi-class predictions. Comparisons of the model alongside both Gagné's (2019) and Conley and Wilson's (2018) work, as well as personal coffee journals, show that predictive results are reproducible. Thus, despite what appears to be a low overall accuracy rate, model performance is not so prohibitive to suggest that the combination of attributes cannot produce a reliable result.

### Findings and Implications

Contextualizing the model's results within the dataset is a complex endeavour. While measuring the model's accuracy against individual coffees is useful to quantify the model's quality on the whole, the prevalence of three Tasting Groups is not necessarily a good determinate of any set of coffee attributes. To draw any valid conclusions, a set of coffee attributes needs to have a low diversity of Tasting Groups _and_ the model needs to predict the most frequent (or majority) of Tasting Groups as they appear within the dataset.

Two coffees within **Figure \@ref(fig:treemap)** show a simplified version of this problem. The first, Costa Rica + Caturra + Natural, is predicted by the model to taste of Other Fruit, Berry Fruit, and Nutty. The first two Tasting Groups are the most frequent (and thus largest squares within the figure), but Body, Brown Sugar, Dried Fruit, and Vanilla are equally as frequent as Berry Fruit (all coloured as light green), and the third model prediction, Nutty, does not appear at all. As such, the predicted Tasting Groups represent the minority of occurring Tasting Groups (the overall square describing the coffee's attributes is less than half of the predicted Tasting Groups). This suggests that the model does not represent these coffees with sufficient nuance; simply put, there are too many other valid Tasting Groups for the itemset. 

This can be contrasted with Costa Rica + Catuai + Honey, where Other Fruit, Brown Sugar, and Stone Fruit (the model predictions) represent the majority of occurring Tasting Groups (only Dried Fruit occurs more frequently). Conclusions made based on the model's outcomes for this attribute set will be more reliable as the coffees show less Tasting Group diversity. 

```{r treemap, out.height="80%", fig.align="center", fig.cap="Treemap of Costa Rican Coffee's Tasting Groups as they Appear within the Dataset"}
treemap(tree %>% group_by(TastingGroup, ItemSet) %>% summarize(n = n()) ,
        index=c("ItemSet", "TastingGroup"),
        vSize="n",
        type="comp",
        title = '',
        align.labels = list(c("left", "top"), c("left", "bottom")),
        overlap.labels	= 1, 
        position.legend	= 'none')
```

This effect is problematic. When examining the model, several well-known Tasting Group combinations for coffee attribute sets appeared to be correct (e.g, Kenya + SL28 + Washed). However, it is difficult to say whether this demonstrates consistency or confirmation bias. For lesser-known, more interesting coffee combinations, or highly varying coffee (such as Costa Rica + Catuai + Washed in **Figure \@ref(fig:treemap)**), there is insufficient knowledge (and data) to evaluate predicted values. 

Broader implications, such as using this model within a commercial environment, or using it to inform farming decisions, should be avoided at this time. Accurately describing a coffee's taste alongside its attributes can logically be applied with reinforcement algorithms when customer preferences are known and collected. This dataset is not suitable for this application. In general, if conclusions are to be made at all, they should be made cautiously, with considerable domain knowledge, and with awareness that the model requires a much larger dataset (§Next Steps). 

There is, however, some novelty in the model's creation, and with some optimism, it begins to unravel some of the complications of specialty coffees. Conley and Wilson highlight the importance of accurate models as, "enabl[ing] the development of formal appellations to confirm each country’s unique coffee profile" (2018). The model should not stifle creativity, but instead reaffirm the anecdotes of well-trained coffee tasters, and can serve as evidence when describing coffee complexities to skeptical audiences. 

### Next Steps

As mentioned previously, continued data collection is paramount to develop this model further. Additional sources of weekly data should be produced much in the same way as the original coffee scrapers. One-off entire site scraping is not required, though if suitable and easy-to-scrape sites are identified, the model will improve from greater coffee data depth. Weekly scrapers generally focused on a single roaster, though this was not necessarily intentional. Using a small collection of single roasters was intended to control the quality of coffee, but as specialty coffee has become much more commonplace, new data sources for the same coffees can be identified. A partnership with a group of roasters who could reliably provide data, rather than scraping, is another avenue worth considering. Regardless of source, data richness should be of utmost importance. As discussed, Region is the next most logical variable to be added to the model. Altitude should follow shortly thereafter, but correlation between variables should be considered. 

Region also allows the introduction of conformed GIS data describing a coffee's terroir [@Mighty_2015]. Though regional climates are likely generalizable for all coffee growing Regions, small differences may vastly improve Tasting Group or Tasting Note prediction. Should more coffee roasters begin to regularly provide latitude and longitude pairs for farm locations, the precision of terroir details can substantially improve, and further aid the model's ability to differentiate like-coffees from one another.

In addition to capturing an entire year's coffee harvest and production, the dataset should be considered nascent until at least 2000 coffees have been collected. This strikes a balance between sparsity and zero variance, allowing for the Boosted Tree model to explore relationships between some of these variables. This quantity will also allow for other well-recognized Varieties and Processes to become prevalent within the dataset (e.g. Batian and SL34, Anaerobic and Carbonic). Some filtering to reduce extremely experimental Varieties or Processes will still be required. It may also prove interesting to model coffees beyond their first Variety, especially for frequently occurring itemsets. For example, SL34 is often paired with SL28 in Kenyan Washed coffees. Understanding how slight modifiers, like Ripeness or a second Variety, alter Tasting Groups/Notes could help to delineate coffees that are currently overgeneralized. 

All data collection efforts should aspire to achieve the objective of this study at its conception: predict Tasting _Notes_ rather than Tasting Groups. Tasting Groups, while essential for the success of this project, are still too reductive. Specialty coffees are interesting because of their nuance: a coffee tasting of Apple is quite different than a coffee tasting of Banana, yet both of these are categorized as Other Fruit. For the model to be used for any utilitarian purposes, this nuance must be preserved.

In order to help models predict Tasting Notes, it will likely prove prudent to add a fourth layer to the conformed tasting table to reduce the overall complexity of Tasting Notes. Some Tasting Notes are overly specific: for example, Bosc Pear, White Pear, Baked Pear, Bartlett Pear, Yellow Pear, Asian Pear, and Pear Tart all describe Pear. This has two effects: firstly, it will help the model make nuanced predictions within slightly broader categories; secondly, the increased granularity will provide a clearer sense of how model predictions for coffees with the same Tasting Group should be evaluated (such as the example coffee in **Table \@ref(tab:sampleaccu)**).

With these steps taken, it may become possible to examine whether a specialty coffee’s Tasting Notes can be predicted with both nuance and precision based on the coffee's attributes. The possible applications of this work can benefit producers and farmers by shifting purchases from a one-time transaction to a long-term investment at each stage of the coffee lifecycle, and also to academics exploring coffee composition at the molecular level. Above all else, predictable coffee can benefit consumers, who, with a data-rich cup of coffee, have already begun to promote a seed-to-cup approach and usher in the next wave of coffee: _ethical consumption_.

\newpage

## References

<div id="refs"></div>

\newpage

## Appendix A: Single-Origin Coffee Terminology

Terms within this project have been capitalized to aid in recognition. 

1) Country and Region of production, where the coffee was cultivated. 

2) Variety, the subspecies cultivated through selection (e.g. Typica, Bourbon, Caturra, SL28, Geisha, Heirloom). Variety may also be referred to as varietal, a single instance of a Variety, for example within a crop or a farm, rather than the subspecies. There are an unknown number of Varieties in the world; however, there are a handful of popular, well-identified Varieties whose morphologies are well-documented.

3) Harvest characteristics, including the following: Ripeness colouration (e.g. Black, Red, Orange, Yellow, White—from most to least ripened), farm’s location (latitude and longitude) and terroir (i.e. temperature, rainfall, soil composition, days of sunshine, Altitude [MASL]), season of harvest, and picking methods (e.g. hand, stripping, mechanical). Farmers (sometimes called estate owners) control these factors.

4) Processing (Natural, Washed, Honey, Pulped) and drying (patio, raised, mechanical) methods. Farmers or producers determine these factors, depending on available infrastructure. In the case where farmers are not able to Process and dry their crop, producers (often within co-ops) handle the Processing of beans and are thus sometimes considered the “origin” when multiple lots are collected and Processed simultaneously.

5) Roast, where all beans have been roasted (i.e. have undergone the Maillard Reaction). Roasters determine duration and temperature. Roasters are occasionally referred to as producers, especially within relationship-coffee purchases. For the sake of simplicity and with due consideration of the effect of roast, the scope of this project will endeavour to exclude coffees roasted beyond the “first crack”.

6) Taste, as identified by cupping, to identify Tasting Traits (e.g. Sweet, Fruity, Texture, Roasted, Nutty/Cocoa), Tasting Groups (e.g. Citrus, Berry, Stone Fruits, Brown Sugar, Floral), and Tasting Notes (e.g. Chocolate, Raspberry, Lemon, Black Tea, Hazelnut, Velvety).

## Appendix B: Datasheet for Dataset, v0.1

Available here: https://github.com/mrpotatocode/COFFEE_COFFEE_COFFEE/blob/main/journal/Week8/DataSheet-0.1.md 

## Appendix C: Model Card, v0.1

Available here: https://github.com/mrpotatocode/COFFEE_COFFEE_COFFEE/blob/main/journal/Week12/ModelCard.md 