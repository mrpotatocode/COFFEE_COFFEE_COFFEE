---
title: |
  ![](mrpotatocode_banner.png){width=7in}  
  Coffee & Machine Learning: An Exploration into the Attributes that Define Single-Origin Coffees
author: "Thomas Rosenthal"
date: "April 1, 2021"
header-includes:
   \usepackage{float}
   \floatplacement{figure}{H}
output:
  bookdown::pdf_document2:
    toc: no
    number_sections: false
    extra_dependencies: ["float"]
    latex_engine: xelatex
    fig_caption: yes
  html_document:
    df_print: paged
  github_document:
nocite: '@*'
bibliography: references.bib
csl: apa-6th-edition.csl
thanks: 'Code and data are available at: [github.com/mrpotatocode/COFFEE_COFFEE_COFFEE](https://github.com/mrpotatocode/COFFEE_COFFEE_COFFEE)'
abstract: In this work, a boosted tree model explores whether combinations of unique coffee attributes can predict the taste of specialty coffees. The properties of 550 coffees, collected over a period of four months, include the coffee's country of origin, variety (subspecies), the means by which it was processed, its harvest characteristic (like altitude and season of harvest), and its tastes generated through consistent cupping practices. These defining attributes are used as predictors for 22 distinct tasing groups and then compared to actual speciality coffees and found to often match two out of every three tasting groups provided by coffee roasters.  
urlcolor: blue
always_allow_html: true
---

\newpage

```{r setup, echo=FALSE}
set.seed(42)
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, out.extra = "")
options(scipen=99999)
```


```{r libraries}
library(tidyverse)
library(data.table)
library(here)
library(kableExtra)
library(ggplot2)
library(ggthemes)
library(bookdown)
library(rworldmap)
```

```{r getdata, include=FALSE}
source(paste0(here::here(),"/scripts/build/01_get_data.R"), local = knitr::knit_global())
```

```{r cleandata, include=FALSE}
source(paste0(here::here(),"/scripts/build/02_clean_data.R"), local = knitr::knit_global())
```

```{r modeldata, include=FALSE}
source(paste0(here::here(),"/scripts/analyze/03_xgb_model.R"), local = knitr::knit_global())
```

```{r vizdata, include=FALSE}
source(paste0(here::here(),"/scripts/analyze/04_viz_data.R"), local = knitr::knit_global())
```

## Introduction

Coffee is consumed in every country, is the seventh most valuable agricultural product [@Pendergrast_2010], and supports the livelihood of 125 million people [@Hoffmann_2018]. In many places, the daily coffee ritual signifies a start to the day and a nod to the productive buzz it imbues its consumer. Our appreciation for coffee has helped shape a complex landscape of horticulture, chemistry, food science, and globalised import-export economics. As a result, coffee has never tasted better. Our collective understanding of coffee information has led to phenomenal quality coffee beans and annual championships celebrating the labour and toil of farmers, producers, roasters, and baristas across the world.

### Background

Combining coffee and data science, this exploratory research aims to examine whether a specialty coffee’s Tasting Notes can be predicted by a gradient boosted algorithm based on the coffee's attributes (§Terminology). Several key research studies have explored the relationship between single-origin attributes and their Tasting Notes and thus sit as domain framework for technical applications made here. Exploring Tasting Notes is contingent firstly upon the acceptance of Tasting Notes as objective rather than subjective. This phenomenon has been well-noted by vintners and has likewise been researched with regard to specialty coffee [@Croijmans_Majid_2016]. Research using blind taste and aroma tests generally supports consistency across highly trained panel tasters [@Bhumiratana_Adhikari_Chambers_2011]. The conclusions of Croijmans and Bhumiratana support the contention that Tasting Notes are a combined result of cupping experts’ training and linguistic ability to identify tastes through plain nomenclature. Cupping, following protocols published by the Specialty Coffee Association (2003), serves as the only means for Tasting Note generation across all relevant studies. Standardized cupping routines were thoroughly explored as a case study in Rwanda [@Goldstein_2011] and found to be reliable.

As such, this project is firmly rooted in scientific consensus that tasting notes are consistent in their generation and thus measurable by machine learning models. From this assertion, two previous experiments have explored single-origin coffee Tasting Notes. Firstly, _Coffee Terroir: Cupping Description Profiles and Their Impact Upon Prices in Central American Coffees_ [@Conley_Wilson_2018] combined country of origin and Tasting Notes within a Multiclass Classification Neural Network and examined the attribute coefficients via regression analysis. Secondly, research produced in a blogging side project by Jonathan Gagné (2019) at the University of Montreal exemplifies Varietal:Tasting Note and Processing:Tasting Note relationships.

This work aims to reinforce the anecdotal assumption that curation of specialty coffees creates certain tastes. The industry cultivates (even without intention) a collection of expected Tasting Notes for known attribute combinations that are perceived as desirable by consumers, thus reinforcing the industry’s expectations and further cultivation of Tasting Notes. The results of modelling, as well as its implications are important within the coffee industry; if known attribute combinations directly contribute to desirable Tasting Notes, producers may know the value of a crop before buying and roasting. This has noted implication on price; Traore et al. (2018) highlighted the phenomenon for Pacamara and Caturra varieties.


### Terminology	

As the world’s appetite for coffee has grown, the coffee industry's "Third Wave" movement has flourished. The movement aims to treat coffee as an artisanal product that is carefully curated, where coffee quality is maximized at each stage: farming, producing, roasting, and selling [@Rosenberg_Swilling_Vermeulen_2018]. There is an “obsession” with coffee’s taste and an often-altruistic approach to conducting business [@Pendergrast_2010]. At its pinnacle, single-origin specialty coffee exists beyond a means to caffeinate and instead engages an increasingly discerning consumer.

Under the umbrella term, "Third Wave", coffees within this project are those that have been produced at a "single origin:" coffee that is sourced from a single producer, farm, or crop. These coffees are further graded as "specialty coffee": coffee of the species Coffea arabica that is within the top 20% of graded coffee produced worldwide. Two grading systems are generally utilized: Q-grading, as defined by the Specialty Coffee Association, and sieve grading, where larger beans are generally preferred (with the exception of single-seed “peaberry” coffees). Different countries utilize different grades (e.g. ‘AA,’ 16+, ‘Strictly High Grown,’ ‘Extra Fancy’) but top grades are well distinguished from middle- and commodity-grade coffees [@Hoffmann_2018]. 

Single-origin coffees are intended to be traceable, meaning consumers are privy to the production cycle before purchase. This data is represented by a core of common attributes: 1) Country and region of production; 2) Variety; 3) Harvest characteristics; 4) Processing; 5) Taste; and 6) Roast. Full descriptions of these attributes and their definitions can be found in Appendix A.

## Data

No publicly available coffee dataset was available for this project. **Figure \@ref(fig:workflow)** shows the end-to-end process employed to collect, analyse, model, evaluate, and present this data. This composed of several web scraping processes (§Data Collection) that were then automated and combined into a stable dataset. This dataset was placed alongside a conformed set of Tasting Notes (§Data Conformity) before modelling.

```{r workflow, fig.align="center", fig.cap="Coffee Model Workflow"}
DiagrammeR::grViz(paste0(here::here(),"/scripts/analyze/05_model_flow.dot"))
```

### Data Collection

Coffee data was scraped from four websites over the course of three months, comprising 550 unique coffees from 106 roasters. Data scraping varied by website format: some websites organized each coffee by roaster, so several scrapers were built to scrape data from roasters with consistent formatting across weeks; others were large collections of coffees that were scraped in entirety from top to bottom. Websites were selected by ease of scraping and quality of coffee offerings. Scrapers were generally run once a week and duplicate coffees were discarded, if there were any. Attributes varied by websites and roaster, but core attributes were generally present. Coffees marked as blends, espressos, and/or decaf were removed.  

These scrapers were automated with GitHub Actions to run on a weekly or monthly basis, depending on the frequency at which the coffees were updated on their respective websites. Each scraper produced a .csv file per roaster or site. These .csv files are then added to the existing data, and any duplicates removed. One website, not suitable for scraping but of excellent data richness, had coffee data manually collected from it. Coffee models became significantly more reliable around 500 coffees, so this manual collection was necessary to help achieve this within threshold. 

Data Collection proved a major limitation to this project. Coffee data collection should continue throughout the year to accommodate for coffee harvesting seasons throughout the world. Brazil, the world's largest producer of arabica grade beans, is significantly underrepresented due to the timing of data collection. Furthermore, scraped websites were inconsistent in their coffee listings. Coffee attributes present in one week were not guaranteed for another, nor was the order in which the attributes listed. Data that was unable to conform to the established standards was discarded before modelling in order to prevent erroneous variable relationships (such as a country being listed as a process).

### Data Conformity   

To facilitate the primary focus (predicting Tasting Notes), a conformed table based on the Specialty Coffee Association Taster's Flavor Wheel (2016) (**Figure \@ref(fig:flavorwheel)**) and World Coffee Research Sensory Lexicon (2017) created a hierarchical categorization for Tasting Notes. Tasting Notes were placed into larger Tasting Groups. Tasting Groups were placed into larger Tasting Traits. **Table \@ref(tab:SCAfru)** provides a sample of this relationship for six Tasting Notes within the "Fruity" Tasting Trait. 

```{r SCAfru}
citr <- sample(x = SCAA_Notes %>% filter(Trait == 'Fruity') %>% 
                                 select(Note) %>%unique() %>% unlist(),
                                 size = 6, replace = FALSE)
SCAA_Fake <- subset(SCAA_Notes, Note %in% citr) %>% select(-l_note) %>% 
        mutate(Note = str_to_title(Note)) %>% rename_all( ~ paste0("Tasting ", .x))
kable(SCAA_Fake, caption="Sample SCAA Tasting Wheel Rows", booktabs = TRUE, linesep= "") %>% 
  kableExtra::kable_styling(latex_options = c("stripped", "HOLD_position"))
```

![(#fig:flavorwheel) Specialty Coffee Association Taster's Flavor Wheel, (Courtesy SCA and WCR, Creative Commons Licensing)](./imgs/Coffee_Tasters_Flavor_Wheel.png){width=50%}

New Tasting Notes were added each time the data collection process occurred. A total of 577 Tasting Notes presently exist within 31 Tasting Groups and 10 Tasting Traits. **Figure \@ref(fig:lollipops)** shows the number of Tasting Notes in each Tasting Group, where Tasting Traits are represented by each coloured dot. Not all Tasting Notes were observed within the dataset: some were listed by the Specialty Coffee Association Taster's Flavor Wheel, others were added in anticipation of future coffees (for example, adding "raspberry jam" after "strawberry jam" was observed in the dataset). 427 distinct Tasting Notes were observed in the dataset.
  
```{r lollipops, out.width="66%", fig.align="center", fig.cap="Hierarchy of Tasting Notes, Groups, and Traits"}
g <- SCAA_Notes %>% group_by(Trait,Group) %>% summarise(n=n()) %>% arrange(desc(n)) 

ggplot(g, aes(x=reorder(Group, n) ,y =n, colour = Trait, fill = Trait))+
  #geom_bar(stat="identity") +
  geom_segment(aes(xend=Group, yend=0), colour = "grey") +
  geom_point(size=3.2) +
  ylab("Number of Tasting Notes") +
  xlab("Tasting Group") +
  coord_flip() + 
  theme_clean() +
  #scale_colour_manual(values = c("#372772","#f19953","#0075f2","#e15554","#86bbd8","#fde8c3","#748b75","#730f07","#da8c07","#280003"))
  #scale_colour_manual(values = c("#280003","#034732","#bb4430","#7daf8f","#00458f","#bc9cb0","#f19953","#730f07","#86bbd8","#da8c07"))
  #scale_colour_manual(values = c("#730f07","#034732","#280003","#7daf8f","#bc8e5c","#70b5ff","#bc9cb0","#f19953","#86bbd8","#da8c07"))
  #scale_colour_manual(values = c("#220901","#941b0c","#af3508","#f6aa1c","#034732","#47745c","#8ba085","#86bbd8","#2660a4","#372772"))
  #scale_colour_manual(values = c("#280003","#606d5d","#bc9cb0","#86bbd8","#f6ae2d","#bb4430","#ffe1a8","#2660a4","#f19953","#372772"))
  scale_colour_brewer(palette="Spectral") 
  #scale_fill_brewer(palette="PRGn") 
```

Adding Tasting Notes to the conformed table introduces some subjectivity. While many Tasting Notes were obvious (e.g. black currant is a Berry Fruit), others were difficult to place within a single category (e.g. chocolate orange). Consideration was made to avoid adding any Tasting Traits or Tasting Groups, instead finding space within existing Tasting Groups. Furthermore, some coffee Tasting Notes were less standard, occasionally showing regionality (e.g. pouding chomeur from a Montreal roaster) or brand names (e.g. Kit-Kat). This limitation is less impactful in the model of this study, which predicted Tasting Groups rather than individual Tasting Notes, but would need to be addressed by larger dataset volume or stricter Tasting Note filters (i.e. only accepting certain standard values).

Additionally, the World Coffee Research program's Arabica Coffee Varieties (2019) catalog was used to help standardize coffee varieties. Because the catalog does not cover all countries within the dataset, the most frequent varieties from those countries were included in modelling. Less frequent Varieties, when valid, should be included as the dataset becomes larger. A total of 15 distinct varieties were used within the modelling process.

### Dataset

Scraped .csv files were flexible enough to allow for significant variance in coffees. By nature, coffees are curated by humans; their coffee cherries harvested at various ripeness points, their varieties occasionally blended to offset flavours, their processing a collection of multiple nearby farms. Producers and roasters make an effort to make these variables as transparent as possible. To create a standardized approach to the information rich data, data extraction focused on specific and recurring features. In total 25 variables were collected. Many of these were extremely sparse (less than 1%) and were not used within modelling. 

First, Tasting Notes in both the dataset and the conformed table were stemmed using the `SnowballC` package [@SnowballC]. This removed the need to explicitly list both plural and nonplural forms of Tasting Notes (e.g. strawberry, strawberries). Tasting Notes were also matched using ASCII/TRANSLIT so that accented characters were not matched indiscriminately to non-accented characters (e.g. rosé, rose).

Second, the variable "Ripeness" was extracted from both Variety and Process columns. Ripeness is expressed by colouration (pink, red, yellow, orange, white, black) as a modifier to either column (e.g. pink bourbon). 

Third, Altitude, which was typically expressed in Metres Above Sea Level (MASL), was converted to a numeric value. Values that were presented as a range were averaged (e.g. 2000-2100 = 2050). 

Finally, both Variety and Process columns were parsed in cases where more than one value was presented. This was fairly common for variety, where single-origin farms blend small quantities of other varieties with a primary variety (e.g. caturra + colombia + castillo becomes three columns: Variety1, Variety2, Variety3). It is assumed these values are listed from greatest to least, as occasionally the percentage of each variety is specified, and in these cases the primary variety has always been listed first. These coffees are generally not considered blends when produced by the same farm or producer. Process columns similarly can describe secondary processes performed after main processes (e.g. washed + patio dried becomes two columns: Processing1, Processing2). In these instances, the secondary process describes the drying method, rather than the processing method. In other instances, the secondary process was a synonym for the primary (e.g. natural + dry processed, where, by definition, natural is a dry processing method). The model used only the primary value for both Variety and Process.

Future models aim to incorporate Regions within Countries using a conformed table to create additional nuance; regional differences are well-noted by Hoffmann (2018). Similarly, in instances where Country was not explicitly listed, but rather presumed by Region, a conformed process could provide missing data (e.g. Huehuetenango would indicate Guatemala).

**Figure \@ref(fig:map)** shows coffee frequency by Country prior to frequency filters required by modelling. Ethiopia and Columbia are the most frequent Countries in the dataset; this is expected with considerations of when the data was collected, as Ethiopia and Columbia both have multiple growing seasons that coincided with the data collection period. A total of 25 Countries were represented in the data, out of the 35 coffee-growing Countries discussed by Hoffmann (2018). Hoffmann speaks to several of these countries having extremely limited production, especially for specialty-grade arabica beans, and thus their omission is unsurprising (e.g. Vietnam). 

```{r map, out.width="66%", fig.align="center", fig.cap="Map of Coffees from Each Country in the Dataset"}
mapParams <- mapCountryData(Map, 
                   nameColumnToPlot="n",
                   xlim=bbox(xylims)[1,],
                   ylim=bbox(xylims)[2,],
                   catMethod="pretty",
                   addLegend=FALSE,
                   colourPalette=colourPalette,
                   mapTitle = '',
                   missingCountryCol = gray(.8))

do.call(addMapLegend, c(mapParams,
                       legendWidth=0.75,
                       legendIntervals="data",
                       legendMar=2,
                       legendShrink =0.4))
abline(h=0,lty=2,col='grey')

```

In order to produce more reliable accuracy within models, extremely infrequent Processes, Countries, and Varieties were excluded. This threshold was set at five individual occurrences for each variable. This had a significant effect on the number of Ethiopian coffees included in the model dataset. Ethiopia has a long history of unique Varieties, some of which are endemic to Ethiopia, and the Variety lineage is less established. **Table \@ref(tab:topfreq)** shows the most frequent Countries, Varieties, and Processes following this filtering process.

```{r topfreq}
topfreq_var <- pre_prep_data %>% mutate_all(funs(str_to_title(.))) %>% 
  group_by(Variety1) %>% summarize(n = n()) %>% arrange(desc(n)) %>% top_n(6)
topfreq_cont <- pre_prep_data %>% mutate_all(funs(str_to_title(.))) %>% 
  group_by(Country) %>% summarize(n = n()) %>% arrange(desc(n)) %>% top_n(6)
topfreq_proc <- pre_prep_data %>% mutate_all(funs(str_to_title(.))) %>% 
  group_by(Processing1) %>% summarize(n = n()) %>% arrange(desc(n)) %>% top_n(6)

kable(list(topfreq_cont,topfreq_var,topfreq_proc),
      caption="Frequent Varieties, Countries and Processes", booktabs = TRUE, linesep= "") %>% 
  kableExtra::kable_styling(full_width = FALSE, position = "left") %>% 
  kableExtra::kable_styling(latex_options = "HOLD_position")
```

When Country, Variety, and Process are combined, **Table \@ref(tab:freqcombo)** shows that Columbia + Caturra + Washed coffees are the most frequent. 4 of the 6 most frequent Countries and Varieties are present in the most frequent combinations of attributes; only 2 distinct Processes are present. 

```{r freqcombo}
freqcombo <- unite(pre_prep_data, ItemSet, Country,Variety1,Processing1, sep = " + ") %>% group_by(ItemSet) %>% 
            summarize(n = n()) %>% arrange(desc(n)) %>% top_n(6) %>% mutate_all(funs(str_to_title(.)))
kable(freqcombo, caption="Greatest Combination Frequencies", booktabs = TRUE, linesep= "") %>% 
  kableExtra::kable_styling(latex_options = c("stripped", "HOLD_position"))
```

Processing has a dramatic effect on Tasting Notes [@Hoffmann_2018], and despite large imbalances in unique Processing frequency, the variable is essential to include within modelling. This effect is observable in the data where a roaster offering two distinct Processes for coffee that is otherwise the same, presents two distinct sets of Tasting Notes (**Table \@ref(tab:twocoffees)** as an example). 

```{r twocoffees}
PistaFugi <- data %>% filter(Roaster == 'Pista') %>% filter(Coffeename %like% 'Fugi') %>% 
  mutate_all(funs(str_to_title(.))) %>% select(Roaster, Coffeename, Country, Region, Variety, Processing, Tastingnotes)

kable(PistaFugi, caption="Two Different Processed Coffees", booktabs = TRUE, linesep= "") %>% 
  kableExtra::kable_styling(latex_options = c("stripped", "HOLD_position"))
```

As expressed previously, adding Region to models was desirable. However, combination frequencies (**Table \@ref(tab:freqcomboregion)**) demonstrate the limitations of a dataset this size, where very few regions had more than five frequent occurrences when combined with Variety and Process. 

```{r freqcomboregion}
freqcomboregion <- data %>% distinct() %>% mutate_all(funs(str_to_title(.)))

kable(unite(freqcomboregion, ItemSet, Country,Region,Variety1,Processing1, sep = " + ") %>% 
        group_by(ItemSet) %>% summarize(n = n()) %>% arrange(desc(n)) %>% top_n(5), 
      caption="Combination Frequencies with Region > 5", booktabs = TRUE, linesep= "") %>% 
  kableExtra::kable_styling(latex_options = c("stripped", "HOLD_position"))
```

This sparseness in data also affected the model's ability to predict Tasting Notes. Instead, Tasting Groups were determined to be the next best candidate for prediction, having considerably more nuance than Tasting Traits but still frequently occurring for nearly all class labels. As such, for all coffees in the dataset Tasting Groups were stacked so that a single Tasting Group was the predictor. This process is demonstrated as **Table \@ref(tab:premeltsample)** transforms into **Table \@ref(tab:meltsample)**.  

```{r premeltsample}
sample4 <- pre_prep_data %>% ungroup() %>% mutate(idx = rownames(pre_prep_data)) %>% 
  filter(idx == 4) %>% mutate_all(funs(str_to_title(.))) %>% select(-idx) %>% select(Country, everything()) %>% 
  rename(TastingGroup1 = Group1, TastingGroup2 = Group2, TastingGroup3 = Group3)


kable(sample4, caption="Coffee Sample before Stacking", booktabs = TRUE, linesep= "") %>% 
  kableExtra::kable_styling(latex_options = c("stripped", "HOLD_position"))
```

```{r meltsample}
sample4melt <- pre_prep_data %>% ungroup() %>% mutate(idx = rownames(pre_prep_data)) %>% filter(idx == 4) %>% 
  select(-idx) %>% melt(id.vars=1:3) %>% select(-variable) %>% rename(TastingGroup = value) %>% 
  mutate_all(funs(str_to_title(.))) %>% select(Country, everything())

kable(sample4melt, caption="Coffee Sample after Stacking", booktabs = TRUE, linesep= "") %>% 
  kableExtra::kable_styling(latex_options = c("stripped", "HOLD_position"))
```

**Figure \@ref(fig:tastingfrequencyplot)** shows the frequency of all Tasting Groups following this transformation prior to modelling. Seven Tasting Groups, Other Fruit, Brown Sugar, Stone Fruit, Berry Fruit, Cocoa, and Floral, are much more prominent Tasting Groups than other Tasting Groups. This imbalance has strong influence on the model (§Results), as very few coffees are predicted with Tasting Groups aside from these seven. However, some Tasting Notes are considerably rare for coffees as a whole, but highly frequent for specific coffee attribute combinations, such as Black Tea, an often-curated Tasting Note for Ethiopian coffees [@Hoffmann_2018]. As such, the lack of presence within the overall dataset does not indicate that the Tasting Note will not be predicted.

```{r tastingfrequencyplot, out.width="66%", fig.align="center", fig.cap="Tasting Group Frequency Prior to Modelling"}
g1 <- prep_data %>% group_by(TastingGroup) %>% summarize(n = n()) %>% arrange(desc(n))
g1$Prop <- g1$n/sum(g1$n)

ggplot(g1, aes(x=reorder(TastingGroup, n) ,y =n))+
  geom_bar(stat="identity", fill = "#733524") +
  ylab("Frequency") +
  xlab("Tasting Group") +
  coord_flip() + 
  theme_clean()
```


## Model

Using `tidymodels` [@tidymodels], a workflow for a Gradient Boosted Tree model with an `XGBoost` [@xgboost] engine predicted Tasting Groups using Country, first Varietal, and first Process for all coffees (Predictors: _Variety1_, _Processing1_, _Country._ Outcome: _TastingGroup_). The dataset was split into training and testing sets using a 75/25 non-stratified split. All predictor values were converted to dummy values (as they were all nominal). The Gradient Boosted Tree was tuned using grid search hyperparameterization on the number of trees (trees), the splitting criteria for each node (min_n), the maxiumum depth of trees (tree_depth), and the learning rate between iterations (learn_rate). 256 total parameter combinations were run (four parameters with four selections each, 4^4). During grid search, 10-fold cross validation was performed. The model was then evaluated on the testing dataset before the best parameter set was selected based on the highest ROC accuracy under curve value. The finalized model was then fit to the entire dataset.

XGBoost [@xgboostpaper], uses the same principals as other Gradient Boosted Trees: loss minimization through gradient descent. XGBoost balances the need to explore all base learners (training loss) and the performance requirements of calculating a loss function for each point of gradient descent (regularization). This is achieved by calculating a residual similarity scores after each leaf splitting criteria is evaluated. The node with the greatest information gain (maximum loss reduction) is selected greedily (so not all trees or learning rates are explored). As an ensemble model, each term is added to the previous to adjust error rates created by previous model iterations.

The final prediction, achieved by fitting base learners to the minimum loss by gradient descent is as follows:
$$\hat{y_i} = \sum_{k=1}^TK_{k}(x_{i})$$

* $\hat{y_i}$ is predicted value
* $K$ is the number of K additive functions used to predict the output
* $f_{k}$ is the space of trees (structure: depth, leaf weight)
* $x_{i}$ is the set of attributes defining the tree (the dataset)

Trees are defined by their splitting criteria (leaf weight), structure (tree depth), such that:
$$f_{t}(x_{i}) = w_{q(x)}$$

* $w$ is the leaf weight
* $q(x)$ is the tree structure

XGBoost seeks to minimize its regularized function:
$$L(\phi) = \sum_{i}l(\hat{y_i},y_i) + \sum_{k}\Omega(f_{k})$$

* $l(\hat{y_i},y_i)$ is the difference between prediction and actual

for a loss coefficient (learning rate) as:
$$\Omega(f_t) = \gamma T + \frac12\lambda \sum_{j = 1}^T w_j ^2$$

* $\Omega(f_t)$ is the loss coefficient applied to the the tree
* $\gamma T$ is the number of leaves for the tree
* $\frac12\lambda \sum_{j = 1}^T w_j ^2$ is the Euclidean norm for leaf scores

The ensemble method then is calculated through boosting:

* $\hat{y_i}^{(0)}$ = 0
* $\hat{y_i}^{(1)}$ = $\hat{y_i}^{(0)} + f_{1}(x_{i})$
* $\hat{y_i}^{(2)}$ = $\hat{y_i}^{(1)} + f_{2}(x_{i})$

Until a finalized term is added to the model 
$$\hat{y}^{(t)} = \sum_{i=1}\lambda(y_i,\hat{y_i}^{(t-1)} + f_{t}(x_i)) + \Omega(f_{t})$$

* $\hat{y}^{(t)}$ is the model at training
* $\sum_{i=1}\lambda(y_i,\hat{y_i}^{(t-1)} + f_{t}(x_i))$ adds each boosting function, including the functions add in previous iteration ($\hat{y_i}^{(t-1)}$)
* $f_{t}(x_i)$ as the new function
* $\Omega(f_{t})$ the loss coefficient as previous calculated

As such, **Table \@ref(tab:bestparams)** shows the best selected parameters for the model following hyperparametization through grid search.

```{r bestparams} 
kable(boosted_param %>% select(-'.config'), caption="XGBoost Model Parameters", booktabs = TRUE, linesep= "") %>% 
  kableExtra::kable_styling(latex_options = c("stripped", "HOLD_position"))
```

## Results

The Gradient Boosted Tree model produces ranked predictions (from most to least probable) for 22 Tasting Groups. Because most coffees have three Tasting Notes, the model's three most probable predictions are treated as the overall prediction for any given combination of coffee attributes. Not all Tasting Groups were predicted, generally due to sparsity or lack of differentiation from coffees with more conventional Tasting Groups of the same coffee attributes. **Table \@ref(tab:tgroupaccu)** shows the most frequent predictions compared to their actual frequencies. Other Fruit, a largely catch-all category for the myriad of fruits that present themselves in coffees is both the most frequent Tasting Group in the dataset and the most predicted by the model. The model over-estimates the top four Tasting Groups (Other Fruit, Brown Sugar, Stone Fruit, Citrus Fruit).

```{r tgroupaccu}
pred_freq <- final_accuracy %>% group_by(note) %>% summarise(n = n()) %>% arrange(desc(n)) %>% 
  rename('TastingGroup' = note)
pred_freq$Prop <- pred_freq$n/sum(pred_freq$n)

tgroup_accu <- inner_join(pred_freq, g1, by = 'TastingGroup') %>% select(-n.y) %>% 
  rename('Predictions' = n.x, 'PredictionFreq' = Prop.x, 'ActualFreq' = Prop.y)

kable(tgroup_accu %>% mutate(across(is.numeric, ~ round(., 3))), 
      caption="Model Prediction by Tasting Group", booktabs = TRUE, linesep= "") %>% 
  kableExtra::kable_styling(latex_options = c("stripped", "HOLD_position"))
```

A confusion matrix (**Figure \@ref(fig:confmat)**) run on the conserved test data appears to show that only seven Tasting Groups were predicted. These Tasting Groups coincided with the most frequently occurring Tasting Groups (as shown by **Figure \@ref(fig:tastingfrequencyplot)**). Like **Table \@ref(tab:tgroupaccu)**, Brown Sugar and Other Fruit classes were the most highly predicted results. Confusion matrices only show the most probable prediction for each coffee within the test data. The overall accuracy metrics derivable from this confusion matrix are thus quite low. Berry Fruit, for example, appeared 22 times within the test data, 6 of which were predicted correctly out of 29 total predictions. Thus a precision rate of 0.207 and a recall rate of 0.273. Some classes were never predicted correctly as the most probable prediction (e.g. Dried Fruit). 

![(#fig:confmat) Confusion Matrix](./imgs/confusion_matrix.png){width=70%}

However, both **Table \@ref(tab:tgroupaccu)** and the confusion matrix are poor representations of the model's performance, and the accuracy score for the model cannot be conventionally calculated. Instead, a better accuracy metric must measure the three most probable predictions while simultaneously deemphasizing the order in which Tasting Groups appear. These needs are specific to coffee: Tasting Group order is irrelevant because there is neither standardization (e.g. fruits are listed before sugars) nor hierarchy (i.e. the first note is not more prevalent than the second). Therefore, the most probable prediction does not need to coincide with the first of three Tasting Groups.

All possible unique inputs were provided to the model and the top three most probable predictions were tabulated alongside their actual (truth) values. A Boolean flag checked whether the first predicted value was in any of the three Tasting Groups. This process was repeated for the second and third predicted values. This method also correctly predicts Tasting Groups for coffees that do not have three unique Tasting Groups. Tasting Groups do not need to be unique because they represent the Tasting Notes which are unique (e.g. Black Currant and Raspberry are both Berry Fruits, therefore both the first and second Tasting Group would be Berry Fruit). Because the model cannot predict the same Tasting Group twice, the Boolean flag allowed duplicate Tasting Groups found within a given coffee to be counted for each occurrence of a Tasting Group, as if the model had predicted duplicate values. An example coffee (**Table \@ref(tab:sampleaccu)**) demonstrates the recalculated accuracy metric. For a coffee with given Country + Variety + Process attributes: "Rwanda + Bourbon + Honey", predictions were Brown Sugar, Other Fruit, and Stone Fruit. Actual values were Brown Sugar, Other Fruit, and Other Fruit. Because the model has predicted both Brown Sugar and Other Fruit, the accuracy is 100% for the given set of coffee attributes. 

```{r sampleaccu}
sample_accu <- final_accuracy %>% select(-id) %>% 
  filter(Country == 'rwanda', Variety1 == 'bourbon',Processing1 == 'honey') %>% arrange(idx) %>% 
  select(-Variety1,-Processing1,-Country)

sample_accu <- sample_accu %>% select(-idx) %>% rename("Prediction" = note, "Probability" = value,
                    'TG_Actual1' = Group1,  'TG_Actual2' = Group2, 'TG_Actual3' = Group3, 
                    'TG_Correct1' = Group1_c, 'TG_Correct2' = Group2_c, 'TG_Correct3' = Group3_c) %>% 
  mutate(across(is.numeric, ~ round(., 3)))

kable(sample_accu, caption="Rwanda + Bourbon + Honey Accuracy Measurement", booktabs = TRUE, linesep= "") %>% 
  kableExtra::kable_styling(latex_options = c("stripped", "scale_down", "HOLD_position"))
```

Thus, the total number of true predictions were 534 of 1188 for a model accuracy score of 44.949% (**Table \@ref(tab:accu)**). 

```{r accu}
#model accuracy:
accu <- correct_predictions %>% filter(Var1 == TRUE, Var2 %like% '_c') %>% select(-Var1) %>% transpose(make.names	='Var2')

accu$Correct <- as.numeric(correct_predictions %>% filter(Var1 == TRUE) %>% summarize(freq = sum(Freq)))
accu$Total <- nrow(final_accuracy)
accu$Accuracy <- as.numeric(accu$Correct/accu$Total)

kable(accu %>% mutate(Accuracy = sprintf("%0.3f%%", accu$Accuracy * 100)),  
      col.names = c('TG_Correct1','TG_Correct2','TG_Correct3','TotalCorrect','TotalTastingGroups','Accuracy'), 
      caption="Adjusted Model Accuracy", booktabs = TRUE, linesep= "") %>% 
  kableExtra::kable_styling(latex_options = c("stripped", "HOLD_position"))

```

### Shiny App

The model was placed in a Shiny App (**Figure \@ref(fig:shiny)**) to allow exploration of any given attribute combination. 98 distinct selections were possible, consisting of 20 Countries, 15 Varieties, and 5 Processes. The Shiny App required a user to first select a Country from a dropdown and were then provided the list of possible Varieties within that Country. Processes were then filtered based on Variety selection. Combinations that did not exist within the data could not be passed to the model (as many of these would not occur in the real-world, and thus predictions irrelevant).

The top three model predictions were listed alongside their probability for occurring. For example, a Kenya + SL28 + Washed selection shows a prediction of Other Fruit (21%), Berry Fruit (19%), and Citrus Fruit (11% probability). A new set of parameters could be selected at any time. The Shiny App does not show model accuracy or the degree that Tasting Groups vary within the given set of attributes (§Findings and Implications) in its current design; this should be added in the future in order to give a better sense of confidence to predictions beyond probability. 

![(#fig:shiny) Tasting Note Predictions Shiny App](./imgs/shiny_app.png){width=70%}

The Shiny app was deployed using shinyapps.io by RStudio and is available at: https://mrpotatocode.shinyapps.io/TastingNotePredictions/.

## Discussion

While the results of this study were limited by the size of the dataset that resulted from time constraints, the data scrapers and models developed provide a solid foundation for future research. Evaluating the significance of this work is difficult. Models for certain combinations appear to meet known expectations, and are comparable to previous work by Gagné (varietal + process to predict tasting notes) and Conley and Wilson (country to predict tasting notes). 

Gagné produced Flavor Wheels for five common Varieties (Bourbon, SL28, Heirlooms, Caturra, Geisha) of Washed coffees, and word clouds for 14 Varieties and 11 Processes (five of which were Honey + Ripeness, and two other infrequent but well-known processes - carbonic and anaerobic). Gagné's work did not include prediction, but rather frequency visualizations of 1500 coffees. When comparing these Flavor Wheels to the model, two stand out: Kenya + SL28 + Washed is predominantly Berry Fruit with Other Fruit and Citrus Fruit Tasting Groups; similarly, Ethiopia + Heirloom + Washed is predominantly Floral with Stone Fruit and Citrus Fruit, though Black Tea was not predicted as the dominant Tasting Group. It is difficult to compare beyond SL28 and Heirloom Varieties, which appear almost exclusively in Kenya and Ethiopia, respectively. Varieties that appear throughout the world, such as Bourbon or Caturra, have much more variety in their predictions than Gagné's work, which generalizes Bourbon regardless of Processing or Country of origin.

Conley and Wilson’s models classified Costa Rican Tasting Notes as Stone Fruit (cherry), Sweet/Brown Sugar (sugar cane, brown sugar, syrup, sweet), and Vanilla. Without knowing either Variety or Process, comparisons with the model for the most commonly occurring Costa Rican coffees were Caturra + Washed, Caturra + Natural, Caturra + Honey, and Catuai + Washed. Of these, all predictions produced Brown Sugar as a Tasting Group, and 3 of 4 produced Stone Fruit. Because Conley and Wilson have used a very small subset of Tasting Notes, placing them within Tasting Groups potentially eliminates the nuance of their analysis, while substituting the complexity of this model. This may suggest that coffees are easier to overgeneralize than specifically predict, but without a greater number of Tasting Notes and more specificity of Variety and Process, it is hard to differentiate the model results from one another.  

Since the combination of these two bodies of work has not yet been established elsewhere, the model provides a rudimentary framework for more multi-class predictions. Comparisons of both Gagné's (2019) and Conley and Wilson's (2018) work alongside the model and personal coffee journals show that predictive results are reproducible. Thus, despite what appears to be a low overall accuracy rate, model performance is not so prohibitive to suggest that the combination of attributes cannot produce a reliable result.

### Findings and Implications

Contextualizing the model's results within the dataset is a complex endeavour. While measuring the model's accuracy against individual coffee's is useful to quantify model's quality on the whole, the prevalence of three Tasting Groups is not necessarily a good determinate of any set of coffee attributes. To draw any valid conclusions, a set of coffee attributes need to have a low diversity of Tasting Groups _and_ the model needs to predict the most frequent (or majority) of Tasting Groups as they appear within the dataset.

Two coffees within **Figure \@ref(fig:treemap)** describe a simplified version of this problem. The first, Costa Rica + Caturra + Natural, is predicted by the model to taste of Other Fruit, Berry Fruit, and Nutty. The first two Tasting Groups are the most frequent (and thus largest squares within the figure), but Body, Brown Sugar, Dried Fruit, and Vanilla are equally as frequent as Berry Fruit, and the third model prediction, Nutty, does not appear at all. As such, the predicted Tasting Groups represent the minority of occurring Tasting Groups (the overall square describing the coffee's attributes is less than half of the predicted Tasting Notes). This suggests that the model does not represent these coffees with sufficient nuance; simply put, there is too many other valid Tasting Groups for the itemset. 

This can be contrasted to Costa Rica + Catuai + Honey, where Other Fruit, Brown Sugar, and Stone Fruit (the model predictions) represent the majority of occurring Tasting Groups (only Dried Fruit is highly frequent). Conclusions made based on the model's outcomes for this attribute set will be better as the coffee's show demonstrate less Tasting Group diversity. 

```{r treemap, out.height="80%", fig.align="center", fig.cap="Treemap of Costa Rican Coffee's Tasting Groups as they Appear within the Dataset"}
treemap(tree %>% group_by(TastingGroup, ItemSet) %>% summarize(n = n()) ,
        index=c("ItemSet", "TastingGroup"),
        vSize="n",
        type="comp",
        title = '',
        align.labels = list(c("left", "top"), c("left", "bottom")),
        overlap.labels	= 1, 
        position.legend	= 'none')
```

This effect is problematic. When examining the model, several well-known Tasting Group combinations for coffee attribute sets appeared to be correct (e.g, Kenya + SL28 + Washed). However, it is difficult to say whether this demonstrates consistency or confirmation bias. For lesser-known, more interesting coffee combinations, or highly varying coffee (such as Costa Rica + Catuai + Washed in **Figure \@ref(fig:treemap)**), there is insufficient knowledge (and data) to evaluate predicted values. 

Broader implications, such as using this model within a commercial environment, or using it to inform farming decisions should be avoided at this time. Accurately describing a coffee's taste alongside its attributes can logically be applied to a recommender algorithm when costumer preferences are known and collected. This dataset is not suitable for this application. In general, if conclusions are to be made at all, they should be made cautiously, with considerable domain knowledge, and with awareness that the model requires a much larger dataset (§Next Steps). 

There is, however, some novelty in the models creation and with some optimism, begins to unravel some of the complications of specialty coffees. Conley and Wilson highlight the important of accurate models as, "enabl[ing] the development of formal appellations to confirm each country’s unique coffee profile." (2018) The model should not stifle creativity, but instead reaffirm the anecdotes of well-trained coffee tasters, and can serve as evidence when describing coffee complexities to sceptical audiences. 

### Next Steps

As mentioned previously, continued data collection is paramount to further develop this model. Additional sources of weekly data should be produced much in the same way of the original coffee scrapers. One-off entire site scraping is not required, though if suitable and easy to scrape sites are identified, the model will improve from greater coffee data depth. Weekly scrapers generally focused on a single roaster, though this was not necessarily intentional. Using a small collection of single roasters intended to control the quality of coffee, but as specialty coffee has become much more commonplace, new data sources for the same coffees can be identified. A partnership with a group of roasters who could reliably provide data, rather than scraping should be another avenue worth considering. Regardless of source, data richness should be of utmost importance. As discussed, Region is the next-most-logical variable to be added to the model. Altitude should follow shortly after, but correlation between variables should be considered. 

Region also allows the introduction of conformed GIS data describing a coffee's terroir. Though regional climates are likely generalizable for all coffee growing region, small changes may vastly improve Tasting Group or Tasting Note prediction. Should some coffee roasters begin to regularly provide latitude and longitude pairs for farm locations terroir details can aid in searching for patterns amongst extreme specificity. 

In addition to capturing an entire year's coffee production, the dataset should be considered nascent until at least 2000 coffees have been collected. This strikes a balance between sparsity and zero variance, allowing for the boost trees model to explore relationships between some of these variables. This quantity will also allow for other well-recognized Varieties and Processes to become prevalent within the dataset (e.g. Batian and SL-34, Anaerobic and Carbonic). Some filtering to reduce extremely experimental Varieties or Processes will still be required. It may also prove interesting to model coffees beyond their first Variety, especially for frequently occurring itemsets. For example, SL34 is often paired with SL28 in Kenyan Washed coffees. Understanding how slight modifiers, like Ripeness or a second Variety alter Tasting Groups/Notes could help to delineate coffees that are currently over-generalized. 

All data collection efforts should achieve the original objective of this study was at its conception: predict Tasting _Notes_ rather than Tasting Groups. Tasting Groups, while essential for the success of this project, are still too reductive. Specialty coffees are interesting because of their nuance: a coffee tasting of apple is quite different than a coffee tasting of banana, yet both of these are categorized by Other Fruit. For the model to be used in any utilitarian purposes, this nuance must be persevered.

In order to help models predict Tasting Notes, it will likely prove prudent to add a fourth layer the SCA Tasting Wheel to reduce the overall complexity of Tasting Notes. Some Tasting Notes are overly specific: for example, Bosc Pear, White Pear, Baked Pear, Bartlett Pear, Yellow Pear, Asian Pear, and Pear Tart all describe Pear. This has two effects: firstly, helping the model make nuanced predictions within slightly broader categories; secondly, the increased granularity will provide a clearer sense of how model predictions for coffees with the same Tasting Group should be evaluated (such as the example coffee in **Table \@ref(tab:sampleaccu)**).

With these steps taken, it may become possible to examine whether a specialty coffee’s Tasting Notes can be predicted with both nuance and precision based on the coffee's attributes. The possible applications from this work can benefit producers and farmers by shifting purchases from a one-time transaction to a longer-term investment at each stage of the coffee lifecycle, to academics exploring coffee composition at the molecular level. And of course, predictable coffee can benefit consumers, who, with a data-rich cup of coffee promote a seed-to-cup approach and have begun to propose the next wave of coffee: _ethical consumption_.

\newpage

## References

<div id="refs"></div>

\newpage

## Appendix A: Single-Origin Coffee Terminology

1) Country and region of production, where the coffee was cultivated. 

2) Variety, the subspecies cultivated through selection (e.g. Typica, Bourbon, Caturra, SL28, Geisha, Heirloom). Variety may also be referred to as varietal, a single instance of a variety, for example within a crop or a farm, rather than the subspecies. There are an unknown number of varieties in the world; however, there are a handful of popular, well-identified varieties whose morphologies are well-documented.

3) Harvest characteristics, including the following: Ripeness colouration (e.g. black, red, orange, yellow, white—from most to least ripened), farm’s location (latitude and longitude) and terroir (i.e. temperature, rainfall, soil composition, days of sunshine, Elevation [MASL]), season of harvest, and picking methods (e.g. hand, stripping, mechanical). Farmers (sometimes called estate owners) control these factors.

4) Processing (Natural, Washed, Honey, Pulped) and drying (patio, raised, mechanical) methods. Farmers or producers determine these factors, depending on available infrastructure. In the case where farmers are not able to process and dry their crop, producers (often within co-ops) handle the processing of beans and are thus sometimes considered the “origin” when multiple lots are collected and processed simultaneously.

5) Roast, where all beans have been roasted (i.e. have undergone the Maillard Reaction). Roasters determine duration and temperature. Roasters are occasionally referred to as producers, especially within relationship-coffee purchases. For the sake of simplicity and with due consideration of the effect of roast, the scope of this project will endeavour to exclude coffees roasted beyond the “first crack.”

6) Taste, as identified by cupping, to identify Tasting Traits (e.g. Sweet, Fruity, Texture, Roasted, Nutty/Cocoa), Tasting Groups (e.g. Citrus, Berry, Stone Fruits, Brown Sugar, Floral), and Tasting Notes (e.g. Chocolate, Raspberry, Lemon, Black Tea, Hazelnut, Velvety). Overlap can exist both vertically and horizontally within this hierarchy: sweetness may describe sweet tasting notes like brown or cane sugars; whereas both sweetness and acidity may describe a sweet and citrus taste such as candied lemon. 

## Appendix B: Datasheet for Dataset, v0.1

Available here: https://github.com/mrpotatocode/COFFEE_COFFEE_COFFEE/blob/main/journal/Week8/DataSheet-0.1.md 

## Appendix C: Model Card, v0.1

Available here: https://github.com/mrpotatocode/COFFEE_COFFEE_COFFEE/blob/main/journal/Week12/ModelCard.md 