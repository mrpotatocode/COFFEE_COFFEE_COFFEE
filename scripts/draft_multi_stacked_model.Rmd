---
title: "draft_multi_stacked_model"
author: "Thomas Rosenthal"
date: "21/03/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE}
#library(drake)
library(tidymodels)
library(tidyverse)
library(rvest)
library(data.table)
library(readxl)
library(SnowballC)
library(here)
library(doFuture)
```

```{r}
#function for fread (data.table)
read_plus <- function(flnm) {
    read_csv(flnm) %>% 
        mutate(filename = flnm) %>% 
        rename_with(str_to_title)}

#tasting note folder
tasting_folder = "inputs/data/Conformed/"
```

```{r}
SCAA_Notes = 
  #load tasting notes
    read_xlsx(here::here(tasting_folder,'SCAA_TastingNotes.xlsx'))
```

```{r}
#build check dataframe
SCAA_Note_check = SCAA_Notes %>% 
mutate(note =  str_to_lower(Note), .keep="none")%>% 
mutate(note = str_trim(note, side = c("both", "left", "right"))) %>% 

#remove plurals, basic stemming
mutate(note = wordStem(note)) %>% 
select(note)
```

```{r}
  #load all data and merge it at once
  #amazing writeup on how to do this here: https://stackoverflow.com/questions/11433432/how-to-import-multiple-csv-files-at-once
  raw_data = 
    list.files(path = "../../Automatic_Drip/R/outputs/",
      pattern = "*.csv",
      full.names = T) %>% 
    map_df(~read_plus(.))
  
```

```{r}  
  #check for missing notes
  check_missing_note = 
    raw_data %>% separate(Tastingnotes, into = c("TastingNote1","TastingNote2","TastingNote3"), sep = ",",  remove = FALSE) %>%
      select(TastingNote1,TastingNote2,TastingNote3) %>% 
      gather(key, TastingNotes) %>% 
      select(-key) %>% 
      mutate(note =  str_to_lower(TastingNotes), .keep="none") %>% 
      mutate(note = str_trim(note, side = c("both", "left", "right"))) %>% 
      mutate(note = wordStem(note)) %>% 
      distinct() %>% 
      left_join(SCAA_Note_check %>% transmute(note,note, check = 'yes')) %>%
      replace_na(list(check = 'no')) %>% 
      filter(check == 'no')
```

```{r}
#this will resolve the Sey issue, when done
oldest_sey = raw_data %>% unite(Variety, c(Variety, Varietal), na.rm = TRUE) %>% 
  unite(Processing, c(Processing, Process), na.rm = TRUE) %>% 
  filter(Filename %like% 'SeyArchive') %>% group_by(Filename) %>% arrange_(~ desc(Filename)) %>% filter(group_indices() == 1) %>% ungroup()

newer_seys = raw_data %>% unite(Variety, c(Variety, Varietal)) %>% 
  unite(Processing, c(Processing, Process)) %>% 
  filter(Filename %like% 'SeyArchive') %>% group_by(Filename) %>% arrange_(~ desc(Filename)) %>% filter(group_indices() != 1) %>% ungroup()

#plyr::match_df(newer_seys %>% select(Roaster, Coffeename, Region, Producer, Variety, Processing), 
   #                 oldest_sey %>%  select(Roaster, Coffeename, Region, Producer, Variety,Processing))

#anti_join(newer_seys %>% select(Roaster, Coffeename, Producer, Variety, Processing), 
 #                   oldest_sey %>%  select(Roaster, Coffeename, Producer, Variety,Processing))

sey_achive = oldest_sey #plus the anti join logic later
sey_achive = sey_achive %>% select(-Url, -Filename, -J, -Procesing) %>% 
  mutate(Tastingnotes =  str_to_lower(Tastingnotes)) %>% 
  mutate(Tastingnotes = str_replace_all(Tastingnotes,"/", ", ")) %>% 
  separate(Tastingnotes, into = c("TastingNote1","TastingNote2","TastingNote3"), sep = ",",  remove = FALSE)
```


```{r}
ripes = tibble(words=c('red','yellow','pink','black','white','orange'))

data = raw_data %>% filter(Filename %like% 'SeyArchive' == FALSE) %>% unite(Variety, c(Variety, Varietal), na.rm = TRUE) %>% 
  unite(Processing, c(Processing, Process), na.rm = TRUE) %>% 
  select(-Url, -Filename, -J, -Procesing) %>% distinct() %>% 
  mutate(Tastingnotes =  str_to_lower(Tastingnotes)) %>% 
  mutate(Tastingnotes = str_replace_all(str_replace_all(Tastingnotes,"/", ", ")," & ",", ")) %>% 
  separate(Tastingnotes, into = c("TastingNote1","TastingNote2","TastingNote3"), sep = ",",  remove = FALSE)
data = rbind(data,sey_achive)

data = data %>%
  mutate(TastingNote1 = str_trim(TastingNote1, side = c("both", "left", "right"))) %>% 
  mutate(TastingNote1 = wordStem(TastingNote1)) %>% 
  mutate(TastingNote2 = str_trim(TastingNote2, side = c("both", "left", "right"))) %>% 
  mutate(TastingNote2 = wordStem(TastingNote2)) %>% 
  mutate(TastingNote3 = str_trim(TastingNote3, side = c("both", "left", "right"))) %>% 
  mutate(TastingNote3 = wordStem(TastingNote3)) 

data <- data %>% mutate(TastingNote1 = iconv(TastingNote1, to='ASCII//TRANSLIT'), 
                        TastingNote2 = iconv(TastingNote2, to='ASCII//TRANSLIT'),
                        TastingNote3 = iconv(TastingNote3, to='ASCII//TRANSLIT'))

data = data %>% mutate(Processing = str_to_lower(Processing)) %>% 
  mutate(Red = str_extract(Processing, "red")) %>% 
  mutate(Yellow = str_extract(Processing, "yellow")) %>%
  mutate(Pink = str_extract(Processing, "pink")) %>%
  mutate(Black = str_extract(Processing, "black")) %>%
  mutate(White = str_extract(Processing, "white")) %>% 
  mutate(Orange = str_extract(Processing, "orange")) 

data = data %>% mutate(Variety = str_to_lower(Variety)) %>% 
  mutate(Red = ifelse(is.na(data$Red), str_extract(Variety, "red"), Red)) %>% 
  mutate(Yellow = ifelse(is.na(data$Yellow), str_extract(Variety, "yellow"), Yellow)) %>%
  mutate(Pink = ifelse(is.na(data$Pink), str_extract(Variety, "pink"), Pink)) %>%
  mutate(Black = ifelse(is.na(data$Black), str_extract(Variety, "black"), Black)) %>%
  mutate(White = ifelse(is.na(data$White), str_extract(Variety, "white"), White)) %>% 
  mutate(Orange = ifelse(is.na(data$Orange), str_extract(Variety, "orange"), Orange)) 

data = data %>% mutate(Altitude  = str_replace_all(str_replace_all(str_replace_all(str_replace_all(str_replace_all(str_replace_all(
  Altitude, "m,", " -"), " masl", ""),"masl", "")," m", ""),"m", ""),' - ','-'))
data = data %>% mutate(Altitude = sapply(strsplit(data$Altitude, split = "-", fixed = TRUE), function(k) mean(as.numeric(k))))
data$Altitude[is.nan(data$Altitude)] <- NA

data$Processing = str_replace_all(data$Processing, str_c("\\b", str_c(ripes$words, collapse = "\\b( )?|"), "\\b( )?"), "")
data$Variety = str_replace_all(data$Variety, str_c("\\b", str_c(ripes$words, collapse = "\\b( )?|"), "\\b( )?"), "")

data = data %>% mutate(Processing = str_replace_all(str_replace_all(str_replace_all(str_replace_all(
          Processing,", ", "|"), " - ","|"), "\\/","|"), " and ","|")) %>%   
    separate(Processing, into = c("Processing1"), sep = "\\|",  remove = FALSE)

data = data %>% mutate(Variety = str_replace_all(str_replace_all(str_replace_all(str_replace_all(str_replace_all(str_replace_all(
  Variety, 'ethiopian','ethiopia'),'gesha','geisha'),'v. colombia','colombia'),'parainema','paraneima'),'sl 28','sl28'),'sl-28','sl28'))

data = data %>% mutate(Variety = str_replace_all(str_replace_all(str_replace_all(str_replace_all(str_replace_all(str_replace_all(str_replace_all(
          Variety,", ", "|"), " and ","|"), " \\+ ","|"), "and ","|")," & ","|"),"& ","|"), " - ","|")) %>%   
    separate(Variety, into = c("Variety1","Variety2","Variety3","Variety4"), sep = "\\|",  remove = FALSE)

data = data %>%unite(Ripeness, c(Red, Yellow, Pink, Black, White, Orange), na.rm=TRUE)

data = data %>% mutate(Ripeness = ifelse(Ripeness == 'red_yellow', "orange", Ripeness))

data = data %>% mutate(Country = str_to_lower(Country))

data <- data %>%
   mutate(across(everything(), ~ifelse(.=="", NA, as.character(.))))
```

```{r}
#data %>% group_by(Variety1) %>% summarize(n=n()) %>% filter(n >= 5) 
 
data %>% filter(Variety1 == '')          
```


```{r}
SCAA_Notes <- SCAA_Notes %>% 
mutate(l_note =  str_to_lower(Note))%>% 
mutate(l_note = str_trim(l_note, side = c("both", "left", "right"))) %>% 

#remove plurals, basic stemming
mutate(l_note = wordStem(l_note)) %>% 

#fix encoding
mutate(l_note = iconv(l_note, to='ASCII//TRANSLIT'))
```


```{r}
merged_data =
sqldf::sqldf("select d.*, n1.Trait as Trait1, n1.[Group] as Group1
              ,n2.Trait as Trait2, n2.[Group] as Group2
              ,n3.Trait as Trait3, n3.[Group] as Group3              
              from data d
              left join SCAA_Notes n1 on trim(n1.l_note) = trim(d.TastingNote1)
              left join SCAA_Notes n2 on trim(n2.l_note) = trim(d.TastingNote2)
              left join SCAA_Notes n3 on trim(n3.l_note) = trim(d.TastingNote3)
              ")

```

```{r}
merged_data %>% select(Tastingnotes,TastingNote3,Trait3, ) %>% distinct() %>%  
  filter(is.na(Trait3))
```

```{r}
merged_data = merged_data %>% distinct()

skimr::skim(merged_data)
```

```{r}
##TRAIT 1
pre_prep_data = merged_data %>% select(Variety1, Processing1, Country, Group1, Group2, Group3 ) 

pre_prep_data = pre_prep_data %>% group_by(Variety1) %>% filter(!is.na(Variety1)) %>% 
            filter(n() >= 5) 

pre_prep_data = pre_prep_data %>% group_by(Processing1) %>% filter(!is.na(Processing1)) %>%
            filter(n() >= 5)

```


```{r}
prep_data = melt(pre_prep_data, id.vars=1:3) #id.vars=1:4
prep_data = prep_data %>% drop_na(value) %>% select(-variable) %>% rename('TastingGroup' = value)
```

```{r}
#write to shiny folder with prep_data
path_out = paste0(here::here(), '/Tamatoa/Third/CoffeeModel/data/')

file_name = paste0(path_out, "shiny_data.csv")
write_csv(prep_data,file_name)
```

```{r}
prep_data %>% group_by(TastingGroup) %>% summarize(n = n())

prep_data %>% group_by(Country) %>% summarize(n = n())
prep_data %>% group_by(Variety1) %>% summarize(n = n())
prep_data %>% group_by(Processing1) %>% summarize(n = n())
```

```{r}
all_cores <- parallel::detectCores(logical = FALSE)

registerDoFuture()
cl <- parallel::makeCluster(4) #all_cores
plan(cluster, workers = cl)
```


```{r}
#Rsample pacakge example 
## Create the train and test sets using Rsample
set.seed(42)
tidy_split <- initial_split(prep_data, prop = .75)
tidy_train <- training(tidy_split)
tidy_test <- testing(tidy_split)
tidy_kfolds <- vfold_cv(tidy_train)
```

```{r}
#Recipes package 
## For preprocessing, feature engineering, and feature elimination 
tidy_rec <- recipe(TastingGroup ~., data = tidy_train) %>% 
  step_dummy(all_nominal(), -all_outcomes()) %>% 
  step_zv(all_predictors())

summary(tidy_rec)
```

```{r}
# Parsnip package 
## Standardized api for creating models 
tidy_boosted_model <- boost_tree(trees = tune(),
                                min_n = tune(),
                                learn_rate = tune(),
                                tree_depth = tune()) %>% 
  set_mode("classification") %>% 
  set_engine("xgboost")

tidy_rf_model <- rand_forest(trees = tune(),
                              min_n = tune()) %>% 
  set_mode("classification") %>% 
  set_engine("ranger")

tidy_svm_model <- svm_poly(cost = tune(),
                           scale_factor = tune(),
                           degree = tune()) %>% 
  set_mode("classification") %>% 
  set_engine("kernlab")
```

```{r}
# Dials creates the parameter grids 
# Tune applies the parameter grid to the models 
# Dials pacakge 
boosted_grid <- grid_regular(parameters(tidy_boosted_model), levels = 4)
rf_grid <- grid_regular(parameters(tidy_rf_model), levels = 10)
svm_grid <- grid_regular(parameters(tidy_svm_model), levels = 5)

# Tune package 
boosted_tune <- tune_grid(tidy_boosted_model,
          tidy_rec,
          resamples = tidy_kfolds,
          grid = boosted_grid)

# rf_tune <- tune_grid(tidy_rf_model,
#                       tidy_rec,
#                       resamples = tidy_kfolds,
#                       grid = rf_grid)

# svm_tune <- tune_grid(tidy_svm_model,
#                       tidy_rec,
#                       resamples = tidy_kfolds,
#                       grid = svm_grid)
```

```{r}
#Use Tune package to extract best parameters using ROC_AUC handtill
boosted_param <- boosted_tune %>% select_best("roc_auc")
#boosted_param <- boosted_tune %>% select_best("accuracy")

#rf_param <- rf_tune %>% select_best("roc_auc")
#rf_param <- rf_tune %>% select_best("accuracy")

#svm_param <- svm_tune %>% select_best("roc_auc")
#svm_param <- svm_tune %>% select_best("accuracy")

#Apply parameters to the models
tidy_boosted_model <- finalize_model(tidy_boosted_model, boosted_param)
#tidy_rf_model <- finalize_model(tidy_rf_model, rf_param)
```

```{r}
# Workflow package 
# For combining model, parameters, and preprocessing
boosted_wf <- workflow() %>% 
  add_model(tidy_boosted_model) %>% 
  add_recipe(tidy_rec)

# rf_wf <- workflow() %>% 
#   add_model(tidy_rf_model) %>% 
#   add_recipe(tidy_rec)


```

```{r}
# Yardstick package
# For extracting metrics from the model 
boosted_res <- last_fit(boosted_wf, tidy_split)
#rf_res <- last_fit(rf_wf, tidy_split)

bind_rows(
  boosted_res %>% mutate(model = "xgb")
#,rf_res %>% mutate(model = "rf")
) %>% 
  unnest(.metrics)

boosted_res %>% unnest(.predictions) %>% 
  conf_mat(truth = TastingGroup, estimate = .pred_class)
```

```{r}
# Fit the entire data set using the final wf 
final_boosted_model <- fit(boosted_wf, prep_data)
#saveRDS(final_boosted_model, "../outputs/models/xboost_coffee_trait1_all.rds")
#saveRDS(final_boosted_model, "../outputs/models/xboost_coffee_group_all_v2.rds")
#saveRDS(final_boosted_model, "../outputs/models/xboost_coffee_group_ripe.rds")
```

```{r}
#write to shiny folder with final_boosted_model
path_out = paste0(here::here(), '/Tamatoa/Third/CoffeeModel/data/')

model_name = paste0(path_out, "xboost_coffee_group_all_v2.rds")
saveRDS(final_boosted_model,model_name)
```

```{r}
boosted_res %>% mutate(model = "xgb") %>% 
  unnest(.metrics) 
```

```{r}
#boosted_res %>% unnest(.notes)
```

```{r}
conf_mat_b <- boosted_res %>% unnest(.predictions) %>% 
  conf_mat(truth = TastingGroup, estimate = .pred_class)
```

```{r}
`<|°_°|>` <-  autoplot(conf_mat_b, type = "heatmap") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

png("../Discussions/imgs/confusion_matrix.png")
print(`<|°_°|>`)
dev.off()

`<|°_°|>`
```




```{r}
#calculate accuracy
# library(plyr)
 path = paste0(here::here(),'/outputs/models/xboost_coffee_group_all_v2.rds')
# 
# #load model
 model <-  readRDS(path)
# 
# #make cartesian join of all coffee combinations 
# v_country <- c('Honduras','Guatemala','Kenya','Colombia','Costa Rica','Brazil','Mexico',
# 'Burundi','Nicaragua','Papua New Guinea','Rwanda','Peru','Panama','Ethiopia',
# 'El Salvador','Tanzania','Bolivia','Ecuador')
# v_var <-  c('Bourbon','Catuai','Caturra','Castillo','Pacas','SL28','Heirloom',
# 'Typica','Colombia','Ethiopia Heirloom','Ethiopian Landrace','V. Colombia')
# v_proc <- c('Honey','Washed','Natural','Sundried','Fully Washed')
# 
# selected = expand.grid(Variety1 = str_to_lower(v_var), Processing1 = str_to_lower(v_proc), Country = str_to_lower(v_country))

#selected = sqldf::sqldf('select distinct s.* from selected s 
#                        join pre_prep_data p on s.Variety1 = p.Variety1 and s.Processing1 = p.Processing1 and s.Country = p.Country')


selected = prep_data %>% select(Variety1,Processing1,Country) %>% filter(!is.na(Country)) %>% distinct()


motha_frockin_accuracy_n_shiz <- data.frame()
for(i in 1:nrow(selected)){
 answer <- predict(
        final_boosted_model,
        selected %>% dplyr::slice(i),
        type = "prob"
    ) %>% 
        gather() %>% 
        arrange(desc(value)) %>% 
        top_n(3)
  
  motha_frockin_accuracy_n_shiz <- rbind(motha_frockin_accuracy_n_shiz,answer)
  print(paste0( i," of ", nrow(selected), " done"))
}
motha_frockin_accuracy_n_shiz$id <- c(0, rep(1:(nrow(motha_frockin_accuracy_n_shiz)-1)%/%3))
motha_frockin_accuracy_n_shiz$id <- motha_frockin_accuracy_n_shiz$id+1

motha_frockin_accuracy_n_shiz <- motha_frockin_accuracy_n_shiz %>% mutate(note = key %>% str_remove(".pred_"))

motha_frockin_accuracy_n_shiz <- motha_frockin_accuracy_n_shiz %>% select(note, everything()) %>% select(-key)
    
dis_it <- merge(motha_frockin_accuracy_n_shiz,mutate(selected, id = rownames(selected)))

le_fin <- sqldf::sqldf('select distinct s.*,Group1,Group2,Group3 from dis_it s 
              join pre_prep_data p on s.Variety1 = p.Variety1 and s.Processing1 = p.Processing1 and s.Country = p.Country')

le_fin <- le_fin %>% mutate(Group1_c = note == Group1, Group2_c = note == Group2, Group3_c = note == Group3)

skimr::skim(le_fin)

x <- table(le_fin=='TRUE', names(le_fin)[col(le_fin)])

#model accuracy:
(x[2,3] + x[2,5] + x[2,7])/nrow(le_fin)
```

```{r message=FALSE}
library(treemap)

treemap(prep_data %>% group_by(TastingGroup, Variety1) %>% summarize(n = n()),
            index=c("TastingGroup",'Variety1'),
            vSize="n",
            type="index"
            )

treemap(prep_data %>% group_by(TastingGroup, Country) %>% summarize(n = n()),
            index=c("TastingGroup",'Country'),
            vSize="n",
            type="index"
            )

treemap(prep_data %>% group_by(TastingGroup, Processing1) %>% summarize(n = n()),
            index=c("TastingGroup",'Processing1'),
            vSize="n",
            type="index"
            )



```