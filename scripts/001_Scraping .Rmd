---
title: "001_Scraping"
author: "Thomas Rosenthal"
date: "28/01/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir  = '..')
```

read in the libraries
```{r warning=FALSE}
library(tidyverse)
library(rvest)
library(lubridate)
library(stringr)
library(data.table)
```

```{r}
rundate = toString(sapply(date(now()), gsub, pattern = "-", replacement = "", fixed = TRUE))
```

get and save data
```{r}
#run line first
#then save (block 2)
#then comment out

raw_data <- read_html("https://eightouncecoffee.ca/collections/monogram-coffee")
write_html(raw_data,paste0("inputs/data/EightOunce/Monogram_" ,rundate, ".html"))
```

```{r}
raw_data <- read_html(paste0("inputs/data/EightOunce/Monogram_" ,rundate, ".html"))

Roaster <- tibble("https://eightouncecoffee.ca/collections/monogram-coffee") %>% 
  separate(1, into = c("1","Roaster"), sep = "collections/",  remove = TRUE) %>% 
  select(-1) %>% 
  sapply(gsub, pattern = "-", replacement = " ", fixed = TRUE) %>% 
  tools::toTitleCase()
```

look at the text
```{r}
slightly_cleaned_data <- 
raw_data %>% 
  #html_nodes("body") %>%
  #html_nodes("div [class='transition-body']") %>% 
  #html_nodes("main") %>%
  #html_nodes("div [class='grid-product__content']") %>% 
  #html_nodes("div [class='grid-product__title grid-product__title--heading']") %>% 
  html_nodes("div [class='grid-product__content']") %>% 
  html_text()
slightly_cleaned_data
```

deal with the character vector
```{r}
our_data <- 
tibble(raw_text = slightly_cleaned_data)
our_data
```


parse, focus on the blank line string:
```{r}
# 
# our_data <- our_data %>% 
#   mutate(is_TLS = if_else(raw_text %like% "\n\n\n\n\n\n\n ",1,0)) %>% 
#   filter(is_TLS == 1) 
```

just get the coffee name
```{r}
coffee_names <- our_data %>% 
  #separate(raw_text, into = c("1","2","3","4","5","6","7","8","9","Name"), sep = "\\n",  remove = TRUE)  %>% 
  rename(Name = raw_text) %>% 
  select(Name) %>%
  mutate(lower_name =  str_to_lower(Name)) %>% 
  mutate(is_blend = if_else(lower_name %like% "blend",1,0),
         is_espresso = if_else(lower_name %like% "espresso",1,0),
         is_decaf = if_else(lower_name %like% "decaf",1,0)) %>% 
  filter(is_blend != 1, is_espresso != 1, is_decaf != 1) %>% 
  select(-is_blend, -is_espresso, -is_decaf)
coffee_names
```

covert to hypenated words (e.g. 'the-library-specialty-coffee-ethiopia-chelelektu-washed')
add prefix: 'https://eightouncecoffee.ca/collections/monogram-coffee/products/'
```{r}
hypenated_data <- coffee_names %>% select(lower_name) %>% 
  apply( MARGIN = 2, FUN = trimws) %>% 
  sapply(gsub, pattern = " ", replacement = "-", fixed = TRUE) %>% 
  sapply(gsub, pattern = ",", replacement = "", fixed = TRUE) %>%
  sapply(gsub, pattern = "---", replacement = "-", fixed = TRUE) %>%
  as.data.frame() %>% 
  rename(Hypen_Name = 1) 
  

hypenated_data$URL <- paste0("https://eightouncecoffee.ca/collections/monogram-coffee/products/",hypenated_data[,1])


hypenated_data <- cbind(lower_name = rownames(hypenated_data), hypenated_data) 
rownames(hypenated_data) <- 1:nrow(hypenated_data)
hypenated_data
```

generate URLs
```{r}
URLs <- hypenated_data$URL
```

remove any URLs that resolve to 404/similar
```{r}
checkURLs <- lapply(URLs, function(u) {
  tryCatch({
    html_obj <- read_html(u)
    draft_table <- html_nodes(html_obj,'table')
    cik <- substr(u,start = 41,stop = 47)
    draft1 <- html_table(draft_table,fill = TRUE)
    final <- u
  }, error = function(x) NULL)
})

URLs <-  unlist(checkURLs)
```

create table for each coffee from URLs
```{r}
coffee_table <- data.frame()
cnt <- 0

for(i in URLs){
  coffee_row <- read_html(i)
  cnt <- cnt+1
  
  #dig into body table
  slightly_cleaned_coffee <- 
  coffee_row %>% 
    html_nodes("div [id='content']") %>%
    html_nodes("ul") %>%
    html_nodes("li") %>%
    html_nodes("p") %>%
    html_text()
  
  write_html(coffee_row,paste0("inputs/data/EightOunce/Coffees/Monogram_", cnt, "_" ,rundate, ".html"))
  
  #deal with the character vector
  coffee <- 
  tibble(raw_text = slightly_cleaned_coffee)
  
  #seperate details row into relevent columns
  coffee <- coffee %>%
    pivot_wider(names_from = 1, values_from = raw_text) %>% 
    rename(table = 1) %>%   #, detail1 = 2, detail2 = 3, detail3 = 4, detail4 = 5 -- some investigation into how to make this dynamic?
    separate(table, into = c("1","Region","Variety","Processing","TastingNotes"), sep = "\\w+:",  remove = TRUE) %>% 
    select("Region","Variety","Processing","TastingNotes")  
    
  coffee$URL <- i
  
  for (i in nrow(coffee)) {
      coffee_table <- rbind(coffee_table, data.frame(coffee))
  }
  Sys.sleep(2.5)
}
```


```{r}
coffee_table$Country <- sapply(strsplit(coffee_table$Region, ","), function(x) trimws(x[length(x)]))
```

consider later? parsename 
```{r}
# x = coffee_table$Region
# x
# 
# xx <- Ecfun::parseName(x,surnameFirst=TRUE)
# xx
# xxx <-  Ecfun::parseName(xx[,2],surnameFirst=TRUE)
# xxx
# merge(xx[,1],xxx,by=0)
```


```{r}
coffee_table
```

```{r}
coffee_names <- coffee_names %>% 
  separate(Name, into = c("Roaster","CoffeeName"), sep = case_when("Name" %like% "Monogram " ~ "Monogram ",
                                                                   TRUE ~ "Monogram "), remove = TRUE)
coffee_names
```

```{r}
filtered_URLs <- merge(hypenated_data,URLs, by.x='URL', by.y ='y', all=FALSE)
```



```{r}
coffee_names$Roaster <-Roaster

newCoffeeName <- coffee_names %>% select(CoffeeName) %>% 
  sapply(gsub, pattern = "-", replacement = "", fixed = TRUE) %>% 
  apply( MARGIN = 2, FUN = trimws) %>% 
  as.data.frame()

coffee_names$CoffeeName = newCoffeeName[,1]

filtered <- merge(filtered_URLs,coffee_names, by='lower_name')
coffee_names <- filtered %>% select(Roaster, CoffeeName, URL)
```


```{r}
final <- merge(coffee_names, coffee_table, by='URL', all=TRUE) %>% select(-URL)
final
```

write to csv
```{r}
path_out = paste0(getwd(),'/outputs/')

file_name = paste0(path_out, 'EightOunce_Monogram_',rundate,".csv")

write_csv(final,file_name)
```

